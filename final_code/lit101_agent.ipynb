{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:26.930084Z",
     "start_time": "2024-09-25T18:18:26.927811Z"
    }
   },
   "source": [
    "#!pip install gym\n",
    "#!pip install tensorflow[and-cuda]\n",
    "#!pip install pygame"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:26.942431Z",
     "start_time": "2024-09-25T18:18:26.940183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set tf warning level to 2 ....shows errors but not warnings\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "#tf.__version__"
   ],
   "id": "72861eebc814b36f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:28.492149Z",
     "start_time": "2024-09-25T18:18:26.992418Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from gym import Env\n",
    "from gym.spaces import Discrete, Box\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "#print(tf.config.functions_run_eagerly())\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "#from rl.agents import DQNAgent\n",
    "#from rl.policy import BoltzmannQPolicy\n",
    "#from rl.memory import SequentialMemory\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "\n",
    "# tyr legacy adam due to numpy error\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import pygame\n",
    "\n",
    "# Set the random seed\n",
    "seed_value = 40\n",
    "np.random.seed(seed_value)\n",
    "random.seed(seed_value)"
   ],
   "id": "89483b04081c5e6e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:28.611539Z",
     "start_time": "2024-09-25T18:18:28.504299Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if TensorFlow is built with CUDA support\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"CUDA is available\")\n",
    "    print(f\"Device: {tf.config.list_physical_devices('GPU')[0]}\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")"
   ],
   "id": "66dae882324f6dbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available\n",
      "Device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727288308.580735  231901 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727288308.604959  231901 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727288308.606921  231901 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Create Environment"
   ],
   "id": "8b45b612b25fa240"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:28.852516Z",
     "start_time": "2024-09-25T18:18:28.663926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ubuntu\n",
    "df_normalised = pd.read_csv(\"/home/loz/Documents/GitHub/MSc-Project/SWaT_12_23_sec_minmax.csv\", index_col='time_in_seconds')\n",
    "data_array = df_normalised.to_numpy()\n",
    "#df_normalised.shape"
   ],
   "id": "7f882fb888e5454b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:28.883413Z",
     "start_time": "2024-09-25T18:18:28.868030Z"
    }
   },
   "cell_type": "code",
   "source": "df_normalised",
   "id": "4270862575c1a5ca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                 FIT101    LIT101  MV101  P101    AIT201    AIT202    AIT203  \\\n",
       "time_in_seconds                                                                \n",
       "0                   0.0  0.990606    0.5   1.0  1.000000  0.128753  0.498588   \n",
       "1                   0.0  0.989536    0.5   1.0  1.000000  0.128753  0.499496   \n",
       "2                   0.0  0.989536    0.5   1.0  1.000000  0.128753  0.501614   \n",
       "3                   0.0  0.989417    0.5   1.0  0.966105  0.125893  0.504035   \n",
       "4                   0.0  0.988585    0.5   1.0  0.966105  0.125893  0.507466   \n",
       "...                 ...       ...    ...   ...       ...       ...       ...   \n",
       "86395               0.0  0.984067    0.5   0.0  0.105092  0.143060  0.049132   \n",
       "86396               0.0  0.983948    0.5   0.0  0.105092  0.143060  0.049132   \n",
       "86397               0.0  0.983591    0.5   0.0  0.105092  0.143060  0.048931   \n",
       "86398               0.0  0.984542    0.5   0.0  0.105092  0.143060  0.048931   \n",
       "86399               0.0  0.985375    0.5   0.0  0.105092  0.143060  0.048931   \n",
       "\n",
       "                   FIT201  MV201  P203  ...    AIT504    FIT501    FIT502  \\\n",
       "time_in_seconds                         ...                                 \n",
       "0                0.769136    1.0   0.0  ...  0.686274  0.566850  0.541283   \n",
       "1                0.863706    1.0   1.0  ...  0.686274  0.566850  0.421003   \n",
       "2                0.916761    1.0   1.0  ...  0.686274  0.566850  0.408771   \n",
       "3                0.952045    1.0   1.0  ...  0.686274  0.566850  0.460754   \n",
       "4                0.974452    1.0   1.0  ...  0.686274  0.566850  0.580023   \n",
       "...                   ...    ...   ...  ...       ...       ...       ...   \n",
       "86395            0.000000    0.5   0.0  ...  0.274513  0.633712  0.428134   \n",
       "86396            0.000000    0.5   0.0  ...  0.274513  0.633712  0.405708   \n",
       "86397            0.000000    0.5   0.0  ...  0.274513  0.598830  0.509681   \n",
       "86398            0.000000    0.5   0.0  ...  0.274513  0.590120  0.605505   \n",
       "86399            0.000000    0.5   0.0  ...  0.274513  0.563947  0.570848   \n",
       "\n",
       "                   FIT503    FIT504    PIT501    PIT502    PIT503    FIT601  \\\n",
       "time_in_seconds                                                               \n",
       "0                0.429823  0.344541  0.390927  0.238806  0.402412  0.000000   \n",
       "1                0.429823  0.546218  0.382286  0.238806  0.402412  0.000000   \n",
       "2                0.429823  0.546218  0.360690  0.238806  0.400006  0.000000   \n",
       "3                0.622810  0.546218  0.360690  0.238806  0.378318  0.000000   \n",
       "4                0.622810  0.546218  0.388771  0.238806  0.378318  0.000000   \n",
       "...                   ...       ...       ...       ...       ...       ...   \n",
       "86395            0.429823  0.319327  0.449245  0.268657  0.431319  0.000037   \n",
       "86396            0.429823  0.319327  0.421165  0.268657  0.431319  0.000037   \n",
       "86397            0.429823  0.319327  0.421165  0.268657  0.395178  0.000037   \n",
       "86398            0.429823  0.319327  0.421165  0.268657  0.395178  0.000037   \n",
       "86399            0.429823  0.319327  0.401726  0.268657  0.383131  0.000037   \n",
       "\n",
       "                 P602  \n",
       "time_in_seconds        \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "86395             0.0  \n",
       "86396             0.0  \n",
       "86397             0.0  \n",
       "86398             0.0  \n",
       "86399             0.0  \n",
       "\n",
       "[86400 rows x 37 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>MV201</th>\n",
       "      <th>P203</th>\n",
       "      <th>...</th>\n",
       "      <th>AIT504</th>\n",
       "      <th>FIT501</th>\n",
       "      <th>FIT502</th>\n",
       "      <th>FIT503</th>\n",
       "      <th>FIT504</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P602</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time_in_seconds</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.990606</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128753</td>\n",
       "      <td>0.498588</td>\n",
       "      <td>0.769136</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686274</td>\n",
       "      <td>0.566850</td>\n",
       "      <td>0.541283</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>0.344541</td>\n",
       "      <td>0.390927</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.402412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989536</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128753</td>\n",
       "      <td>0.499496</td>\n",
       "      <td>0.863706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686274</td>\n",
       "      <td>0.566850</td>\n",
       "      <td>0.421003</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>0.382286</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.402412</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989536</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128753</td>\n",
       "      <td>0.501614</td>\n",
       "      <td>0.916761</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686274</td>\n",
       "      <td>0.566850</td>\n",
       "      <td>0.408771</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>0.360690</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.400006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989417</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966105</td>\n",
       "      <td>0.125893</td>\n",
       "      <td>0.504035</td>\n",
       "      <td>0.952045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686274</td>\n",
       "      <td>0.566850</td>\n",
       "      <td>0.460754</td>\n",
       "      <td>0.622810</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>0.360690</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.378318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988585</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.966105</td>\n",
       "      <td>0.125893</td>\n",
       "      <td>0.507466</td>\n",
       "      <td>0.974452</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.686274</td>\n",
       "      <td>0.566850</td>\n",
       "      <td>0.580023</td>\n",
       "      <td>0.622810</td>\n",
       "      <td>0.546218</td>\n",
       "      <td>0.388771</td>\n",
       "      <td>0.238806</td>\n",
       "      <td>0.378318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984067</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105092</td>\n",
       "      <td>0.143060</td>\n",
       "      <td>0.049132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274513</td>\n",
       "      <td>0.633712</td>\n",
       "      <td>0.428134</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>0.319327</td>\n",
       "      <td>0.449245</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.431319</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983948</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105092</td>\n",
       "      <td>0.143060</td>\n",
       "      <td>0.049132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274513</td>\n",
       "      <td>0.633712</td>\n",
       "      <td>0.405708</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>0.319327</td>\n",
       "      <td>0.421165</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.431319</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.983591</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105092</td>\n",
       "      <td>0.143060</td>\n",
       "      <td>0.048931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274513</td>\n",
       "      <td>0.598830</td>\n",
       "      <td>0.509681</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>0.319327</td>\n",
       "      <td>0.421165</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.395178</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.984542</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105092</td>\n",
       "      <td>0.143060</td>\n",
       "      <td>0.048931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274513</td>\n",
       "      <td>0.590120</td>\n",
       "      <td>0.605505</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>0.319327</td>\n",
       "      <td>0.421165</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.395178</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.985375</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105092</td>\n",
       "      <td>0.143060</td>\n",
       "      <td>0.048931</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.274513</td>\n",
       "      <td>0.563947</td>\n",
       "      <td>0.570848</td>\n",
       "      <td>0.429823</td>\n",
       "      <td>0.319327</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>0.268657</td>\n",
       "      <td>0.383131</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86400 rows × 37 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:28.936677Z",
     "start_time": "2024-09-25T18:18:28.934091Z"
    }
   },
   "cell_type": "code",
   "source": "data_array[35].max()",
   "id": "7f9b7fd3fbd6dbc6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "2e77426240355b11"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:28.990742Z",
     "start_time": "2024-09-25T18:18:28.987750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "component_pos = {key: idx for idx, key in enumerate(df_normalised.columns)}\n",
    "component_pos.items()"
   ],
   "id": "d374679f3925cbdc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('FIT101', 0), ('LIT101', 1), ('MV101', 2), ('P101', 3), ('AIT201', 4), ('AIT202', 5), ('AIT203', 6), ('FIT201', 7), ('MV201', 8), ('P203', 9), ('P205', 10), ('DPIT301', 11), ('FIT301', 12), ('LIT301', 13), ('MV301', 14), ('MV302', 15), ('MV303', 16), ('MV304', 17), ('P301', 18), ('P302', 19), ('AIT401', 20), ('AIT402', 21), ('FIT401', 22), ('LIT401', 23), ('AIT501', 24), ('AIT502', 25), ('AIT503', 26), ('AIT504', 27), ('FIT501', 28), ('FIT502', 29), ('FIT503', 30), ('FIT504', 31), ('PIT501', 32), ('PIT502', 33), ('PIT503', 34), ('FIT601', 35), ('P602', 36)])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:29.086442Z",
     "start_time": "2024-09-25T18:18:29.083392Z"
    }
   },
   "cell_type": "code",
   "source": "data_array[component_pos['LIT101']]",
   "id": "ef6622de8b9b58c5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.9895364 , 0.5       , 1.        , 1.        ,\n",
       "       0.12875348, 0.49949565, 0.86370641, 1.        , 1.        ,\n",
       "       0.        , 0.97655405, 0.93638966, 0.02859152, 0.5       ,\n",
       "       1.        , 0.5       , 0.5       , 0.        , 1.        ,\n",
       "       0.        , 0.78048858, 0.52452306, 0.18279767, 0.44860876,\n",
       "       0.78728599, 0.65201404, 0.68627361, 0.56685038, 0.42100321,\n",
       "       0.4298233 , 0.54621783, 0.38228633, 0.23880613, 0.40241243,\n",
       "       0.        , 0.        ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:29.843487Z",
     "start_time": "2024-09-25T18:18:29.193428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# test lstm swat simulator\n",
    "# Load the model from the SavedModel directory\n",
    "# 20 secs\n",
    "#swat_lstm = tf.keras.models.load_model('swat_lstm_1_0.keras')\n",
    "#swat_lstm = tf.keras.models.load_model('best_model.keras')\n",
    "#model_window = 20\n",
    "swat_lstm = tf.keras.models.load_model('swat_lstm_100s.keras')\n",
    "model_window = 100"
   ],
   "id": "c2384e58148b04d9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727288309.198639  231901 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727288309.200685  231901 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727288309.202594  231901 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727288309.295397  231901 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727288309.296862  231901 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1727288309.298306  231901 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Agent for single window",
   "id": "3ba5b2cd389cd293"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:29.857121Z",
     "start_time": "2024-09-25T18:18:29.855467Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reshape the input from data_array to add the batch dimension\n",
    "#reshaped_input = data_array[:model_window-1, :].reshape(1, model_window-1, data_array.shape[1])  # (1, 99, 37)\n",
    "# round to make observation space workable\n",
    "#reshaped_input = np.round(reshaped_input, 2)\n",
    "\n",
    "\n",
    "#reshaped_input.shape\n",
    "#reshaped_input[0,-1,]"
   ],
   "id": "b0261b1f6ccf82d2",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "ec64b7b8bf3ced28"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:29.891706Z",
     "start_time": "2024-09-25T18:18:29.889886Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "36edf771995e7183",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# get last row\n",
    "one_state = reshaped_input[0,-1,:]\n",
    "one_state.shape"
   ],
   "id": "14e0fc5c4697e53c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for _ in range(10):\n",
    "    prediction = swat_lstm.predict(reshaped_input)\n",
    "    # Print shape\n",
    "    #print(prediction.shape)\n",
    "    # drop first row from input, add prediction with new axis padded to match shape\n",
    "    reshaped_input = np.concatenate((reshaped_input[:, 1:, :], prediction[:, np.newaxis, :]), axis=1)\n",
    "    #print(reshaped_input.shape)\n"
   ],
   "id": "445f925765d42f47"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:29.935229Z",
     "start_time": "2024-09-25T18:18:29.933617Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a5be63bb26900336",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "prediction = swat_lstm.predict(reshaped_input)",
   "id": "3894c0718e36844b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "def update_state(state_history, action_input):\n",
    "    # add action to previous states\n",
    "    model_input = np.concatenate((state_history[:, 1:, :], action_input[:, np.newaxis, :]), axis=1)\n",
    "    # predict\n",
    "    new_state = swat_lstm.predict(model_input)\n",
    "    return new_state, model_input\n",
    "    \n"
   ],
   "id": "dad169de37debeea"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "new_state, model_input = update_state(reshaped_input, prediction) \n",
    "new_state.shape\n",
    "\n",
    "#new_state[0]=10\n",
    "#new_state"
   ],
   "id": "9fe250298611b60b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:29.979136Z",
     "start_time": "2024-09-25T18:18:29.977316Z"
    }
   },
   "cell_type": "code",
   "source": "#model_input.shape",
   "id": "3e9a9ce0402f5069",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.023983Z",
     "start_time": "2024-09-25T18:18:30.021646Z"
    }
   },
   "cell_type": "code",
   "source": "#reshaped_input.shape",
   "id": "8bfece62622900c2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.073729Z",
     "start_time": "2024-09-25T18:18:30.071014Z"
    }
   },
   "cell_type": "code",
   "source": "data_array.shape",
   "id": "5379535d3e209b95",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86400, 37)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.123664Z",
     "start_time": "2024-09-25T18:18:30.121632Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "1002a215ba960daa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "component_pos['MV201']",
   "id": "629322d44465ff0f"
  },
  {
   "cell_type": "code",
   "source": [
    "# inherit from gym env\n",
    "class SwatEnv(Env):\n",
    "    def __init__(self, data_array, window_size=99, episode_length=100):\n",
    "        print('init reached')\n",
    "        # 0: both off, 1: MV101 On MV201 Off, 2: MV101 Off MV201 On, 3: both on\n",
    "        self.action_space = Discrete(4)\n",
    "        self.episode_length = episode_length\n",
    "        \n",
    "        # make sure array is 3 dims for model input\n",
    "        if len(data_array.shape) == 2:\n",
    "            # Add a batch dimension to make it (1, time_steps, features)\n",
    "            data_array = data_array[np.newaxis, :, :]\n",
    "        \n",
    "        # swat value array, only position 1 used as lit101 level. 2.d.p \n",
    "        self.observation_space = Box(\n",
    "            # round to 2 d.p. to act as binning values\n",
    "            low=np.round(np.full((1, 37), 0.00), 2),  # 1x37 array with all elements set to 0.00\n",
    "            high=np.round(np.full((1, 37), 100.00), 2),  # 1x37 array with all elements set to 100.00\n",
    "            dtype=np.float32  # Specify float with two decimal places precision\n",
    "        )\n",
    "        \n",
    "        # Initialise data params\n",
    "        self.data_array = data_array\n",
    "        self.window_size = window_size \n",
    "        \n",
    "        # use reset to intialise the data window to use \n",
    "        self.reset(data_array)      \n",
    "        \n",
    "        # state history is 98 time steps preceding\n",
    "        #self.state_history = model_input\n",
    "        # set start state as last row in modelinput\n",
    "        #elf.state = self.state_history [0,-1,:]\n",
    "        \n",
    "        # set shower length\n",
    "        self.episode_length = episode_length\n",
    "        \n",
    "        self.lit101_value_record = []\n",
    "    \n",
    "    # Override inherited method  \n",
    "    def sample_observation(self):\n",
    "        return np.round(self.observation_space.sample(), 2)\n",
    "\n",
    "        \n",
    "    def update_state(self, state_history, action_input):\n",
    "        # Ensure action_input is reshaped to 1x37 array\n",
    "        action_input = action_input.reshape(1, -1)\n",
    "        \n",
    "        # add action to previous states\n",
    "        model_input = np.concatenate((state_history[:, 1:, :], action_input[:, np.newaxis, :]), axis=1)\n",
    "        # predict\n",
    "        new_state = swat_lstm.predict(model_input)\n",
    "        new_state = np.round(new_state, 2)\n",
    "        \n",
    "        # prob don't use as new window wanted\n",
    "        # update history with new state\n",
    "        #self.state_history = np.concatenate((state_history[:, 1:, :], new_state[:, np.newaxis, :]), axis=1)\n",
    "        \n",
    "        # flatten new_state from (1,37) to (37,)\n",
    "        new_state = new_state.flatten()\n",
    "        \n",
    "        return new_state\n",
    "        \n",
    "    def step(self, action):\n",
    "        #print(f'step reached {action}')\n",
    "        \n",
    "        # copy current state\n",
    "        action_input = self.state.copy() \n",
    "        \n",
    "        # MV101 \n",
    "        if action == 0:\n",
    "            ## MV101 and MV201 off         \n",
    "            action_input[component_pos['MV101']] = 0\n",
    "            action_input[component_pos['MV201']] = 0\n",
    "            \n",
    "        elif action == 1:\n",
    "            # MV101 On, MV201 Off\n",
    "            action_input[component_pos['MV101']] = 1\n",
    "            action_input[component_pos['MV201']] = 0\n",
    "        elif action == 2:\n",
    "            # MV101 Off, MV201 On\n",
    "            action_input[component_pos['MV101']] = 0\n",
    "            action_input[component_pos['MV201']] = 1\n",
    "        elif action == 3:\n",
    "            # Both MV101 and MV201 On\n",
    "            action_input[component_pos['MV101']] = 1\n",
    "            action_input[component_pos['MV201']] = 1\n",
    "        \n",
    "        new_state = self.update_state(self.state_history, action_input)\n",
    "        # test with no actions\n",
    "        #new_state = self.update_state(self.state_history, self.state.copy())\n",
    "        \n",
    "        \n",
    "        #print(new_state.shape, self.state.shape)\n",
    "        \n",
    "        #record lit101 state\n",
    "        #self.lit101_value_record.append((np.round(new_state[component_pos['LIT101']], 2)))\n",
    "        # get change in value for plotting\n",
    "        \n",
    "        self.lit101_value_record.append(np.round(new_state[component_pos['LIT101']]-self.state[component_pos['LIT101']], 2))\n",
    "\n",
    "                                     \n",
    "        # check for increase\n",
    "        if new_state[component_pos['LIT101']] > self.state[component_pos['LIT101']]:\n",
    "            reward = new_state[component_pos['LIT101']] - self.state[component_pos['LIT101']]\n",
    "        elif new_state[component_pos['LIT101']] == self.state[component_pos['LIT101']]:\n",
    "            reward = -1\n",
    "        elif new_state[component_pos['LIT101']] < self.state[component_pos['LIT101']]:\n",
    "            reward = self.state[component_pos['LIT101']] - new_state[component_pos['LIT101']]\n",
    "            \n",
    "        print(f'lit:{self.state[component_pos['LIT101']], new_state[component_pos['LIT101']]} reward:{reward}')\n",
    "        \n",
    "        # prob not needed as should be reset to new window\n",
    "        # update state\n",
    "        self.state = new_state\n",
    "    \n",
    "        # reduce episode_length\n",
    "        self.episode_length = self.episode_length - 1\n",
    "        \n",
    "        # Check if episode is done\n",
    "        if self.episode_length <= 0:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False         \n",
    "        \n",
    "        return self.state, reward, self.lit101_value_record, done #, info\n",
    "\n",
    "    def reset(self, data_array):\n",
    "        # state history is 98 time steps preceding\n",
    "        #self.state_history = model_input\n",
    "        \n",
    "        # Randomly select new window from data_array for each episode\n",
    "        start_idx = np.random.randint(0, data_array.shape[1] - self.window_size)\n",
    "        self.state_history = data_array[:, start_idx:start_idx + self.window_size, :]\n",
    "        # Set the start state as the last row in the selected window\n",
    "        self.state = self.state_history[0, -1, :]\n",
    "        \n",
    "        # reset episode\n",
    "        #self.episode_length = episode_length\n",
    "        # reset value record\n",
    "        self.lit101_value_record = []\n",
    "        return self.state\n",
    "        \n",
    "    #def render(self):\n",
    "        # for vis ie pygame\n",
    "        #pass\n",
    "    def render(self, screen, font):\n",
    "        '''\n",
    "        screen.fill((255, 255, 255))  # Fill the screen with white\n",
    "\n",
    "        # Draw the temperature meter\n",
    "        pygame.draw.rect(screen, (0, 0, 255), (100, 150, 50, 200))  # Blue background\n",
    "        temp_height = (self.state - 0) / 100 * 200  # Scale temp to meter height\n",
    "        pygame.draw.rect(screen, (255, 0, 0), (100, 350 - temp_height, 50, temp_height))  # Red temperature\n",
    "\n",
    "        # Display temperature value\n",
    "        temp_text = font.render(f'Temp: {self.state}°C', True, (0, 0, 0))\n",
    "        screen.blit(temp_text, (200, 150))\n",
    "\n",
    "        # Display shower length\n",
    "        shower_text = font.render(f'Shower Time: {self.shower_length}s', True, (0, 0, 0))\n",
    "        screen.blit(shower_text, (200, 200))\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "        \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:21:39.802724Z",
     "start_time": "2024-09-25T18:21:39.796512Z"
    }
   },
   "id": "57e0e505639a90cf",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "def main():\n",
    "    # Initialize pygame\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((600, 400))\n",
    "    pygame.display.set_caption(\"SWAT Environment Visualization\")\n",
    "\n",
    "    # Font for rendering text\n",
    "    font = pygame.font.SysFont('Arial', 24)\n",
    "\n",
    "    # Create the environment\n",
    "    env = SwatEnv()\n",
    "\n",
    "    # Initialize game loop variables\n",
    "    running = True\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    state = env.reset()  # Initialize environment state\n",
    "\n",
    "    while running:\n",
    "        # Handle events\n",
    "        for event in pygame.event.get():\n",
    "            if event.type == pygame.QUIT:\n",
    "                running = False\n",
    "\n",
    "        # Action logic (can be random for testing purposes)\n",
    "        action = random.randint(0, 2)  # Replace with your agent's action\n",
    "\n",
    "        # Perform step\n",
    "        state, reward, done, info = env.step(action)\n",
    "\n",
    "        # Render the environment\n",
    "        env.render(screen, font)\n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # End if the shower is done\n",
    "        if done:\n",
    "            state = env.reset()\n",
    "\n",
    "        # Control frame rate (optional)\n",
    "        clock.tick(30)  # 30 FPS\n",
    "\n",
    "    pygame.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "id": "18cf70136b2a62d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:21:40.528789Z",
     "start_time": "2024-09-25T18:21:40.526722Z"
    }
   },
   "cell_type": "code",
   "source": "#reshaped_input[0,11,]",
   "id": "a47b35aec529418d",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:21:40.827665Z",
     "start_time": "2024-09-25T18:21:40.825753Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "97f2c748134a82a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:21:41.058459Z",
     "start_time": "2024-09-25T18:21:41.056652Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "b46416e7267db886",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:21:41.257424Z",
     "start_time": "2024-09-25T18:21:41.254925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# sample from action space\n",
    "#env.action_space.sample()"
   ],
   "id": "4105b29d17c4c342",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:21:41.466168Z",
     "start_time": "2024-09-25T18:21:41.464060Z"
    }
   },
   "cell_type": "code",
   "source": "#env.observation_space.sample()",
   "id": "488605971a80495f",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:21:41.719042Z",
     "start_time": "2024-09-25T18:21:41.716775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# shown as high precision but actually 2 dp....\n",
    "#sampled_obs = env.observation_space.sample()\n",
    "#sampled_obs_rnd = np.round(sampled_obs, 2)\n",
    "#sampled_obs_rnd"
   ],
   "id": "9d5141d7337386af",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "print(env.state.shape)",
   "id": "ea9eebeb40dead8f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "env = SwatEnv(reshaped_input)# store lit101 values form each episode\n",
    "\n",
    "lit101_dict = {}\n",
    "\n",
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    \n",
    "    env.reset(reshaped_input)\n",
    "    state = env.state\n",
    "    done = False\n",
    "    score = 0 \n",
    "    \n",
    "    while not done:\n",
    "        #env.render()\n",
    "        # sample from 4 possible states \n",
    "        #action = env.action_space.sample()\n",
    "        \n",
    "        # just activate MV101 to see if response from lstm model is linear\n",
    "        action = 1\n",
    "        \n",
    "        \n",
    "        # pass 1 x 37 array of SWat states\n",
    "        #action = one_state\n",
    "        #n_state, reward, done, info = env.step(action)\n",
    "        n_state, reward, done = env.step(action)\n",
    "        print(n_state)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode, score))\n",
    "    # add this episodes list of values\n",
    "    lit101_dict[episode] = env.lit101_value_record"
   ],
   "id": "65305113d18bb6e2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for key, value in lit101_dict.items():\n",
    "    plt.plot(value, label=key)\n",
    "\n",
    "plt.legend()    \n",
    "plt.show()"
   ],
   "id": "fdc34eb9e12470be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test with multiple start points",
   "id": "dabbfd2fdebca792"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:21:43.613612Z",
     "start_time": "2024-09-25T18:21:43.610957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#start_idxs = [np.random.randint(0, 1000) for n in range(5)]\n",
    "#start_idxs"
   ],
   "id": "874e522e4d4e8f69",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:21:44.111985Z",
     "start_time": "2024-09-25T18:21:44.108902Z"
    }
   },
   "cell_type": "code",
   "source": "data_array.shape",
   "id": "74082ab71fd207b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86400, 37)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:28:16.935712Z",
     "start_time": "2024-09-25T18:28:16.931908Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_random_trials(environment, data_array, window_size , episode_length, number_of_trials):\n",
    "    ''' Function to set up each trial with a random window'''\n",
    "\n",
    "    values_dict = {}\n",
    "    input_windows = {}\n",
    "    \n",
    "    \n",
    "    data_length = data_array.shape[0]\n",
    "    window_size = model_window - 1\n",
    "    \n",
    "    values_dict = {}\n",
    "    input_windows = {}\n",
    "    \n",
    "    \n",
    "    for trial in range(number_of_trials):\n",
    "    \n",
    "        values_dict[trial] = run_trial(environment,episode_length, number_of_episodes=1)\n",
    "        \n",
    "    return values_dict, input_windows\n",
    "    \n",
    "def run_trial(environment, data_array, window_size, episode_length):\n",
    "    '''\n",
    "    Function to run agent with a given starting point of a data window from the data_set\n",
    "    :param environment: SWaTEnv\n",
    "    :param model_input_window: Random slice of SWaT data in format for LSTM (1,19,37)\n",
    "    :param number_of_episodes: Times to repeat\n",
    "    :return: \n",
    "    '''\n",
    "    \n",
    "    # make sure array is 3 dims for model input\n",
    "    if len(data_array.shape) == 2:\n",
    "        # Add a batch dimension to make it (1, time_steps, features)\n",
    "        data_array = data_array[np.newaxis, :, :]\n",
    "    this_env = environment(data_array, window_size, episode_length)\n",
    "        \n",
    "    # store lit101 values form each episode\n",
    "    #lit101_list = []\n",
    "    \n",
    "    episodes = episode_length\n",
    "    for episode in range(1, episodes+1):\n",
    "        \n",
    "        this_env.reset(data_array)\n",
    "        state = this_env.state\n",
    "        done = False\n",
    "        score = 0 \n",
    "        \n",
    "        while not done:\n",
    "            #env.render()\n",
    "            # sample from 4 possible states \n",
    "            #action = this_env.action_space.sample()\n",
    "            \n",
    "            # just activate MV101 to see if response from lstm model is linear\n",
    "            action = 1\n",
    "            \n",
    "            # pass 1 x 37 array of SWat states\n",
    "            #action = one_state\n",
    "            #n_state, reward, done, info = env.step(action)\n",
    "            n_state, reward, value_change, done = this_env.step(action)\n",
    "            print(n_state)\n",
    "            score+=reward\n",
    "        print('Episode:{} Score:{}'.format(episode, score))\n",
    "        # add this episodes list of values\n",
    "        lit101_list = this_env.lit101_value_record\n",
    "        \n",
    "    return lit101_list\n",
    "    \n",
    "    \n",
    "    #return input_windows\n"
   ],
   "id": "cb02313aec39a8e1",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:28:32.062916Z",
     "start_time": "2024-09-25T18:28:24.908780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "lit101_list = []\n",
    "for _ in range(200):\n",
    "    lit101_li = run_trial(SwatEnv,data_array,model_window,1)\n",
    "    lit101_list.append(lit101_li)"
   ],
   "id": "6af705739fb0e135",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.1414982686373291, -0.19) reward:0.33149826625314327\n",
      "[ 0.84 -0.19  0.83  0.47 -0.67 -0.16 -0.35  0.56  0.53  0.57  1.22  0.72\n",
      "  0.59  1.09  0.23  0.87  0.23 -0.12  0.1   0.63  0.71  0.92  0.4   0.81\n",
      " -0.77  1.03  0.09  0.86  0.41  0.21  0.06 -0.45 -0.14  0.76 -0.09  0.01\n",
      "  0.02]\n",
      "Episode:1 Score:0.33149826625314327\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0338884215443251, -0.48) reward:0.5138884108154891\n",
      "[ 0.82 -0.48  0.78  0.45  0.39  0.99  0.36  0.48  0.48  0.5   1.05  0.62\n",
      "  0.47  0.76  0.24  0.81  0.51  0.08 -0.15  0.54 -0.62 -0.02  0.25  0.49\n",
      "  0.29  0.15  0.95  1.49  0.21  0.06  0.19 -0.17  0.11  0.02  0.17  0.07\n",
      "  0.03]\n",
      "Episode:1 Score:0.5138884108154891\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.989298600460384, 0.74) reward:0.24929859092364082\n",
      "[ 0.11  0.74  0.13  0.46  0.5  -0.08 -0.03  0.47  0.46  0.49  0.64  0.69\n",
      "  0.55  0.76  0.08  0.8  -0.11 -0.18 -0.04  0.66 -0.66 -0.18  0.29  0.17\n",
      "  0.23 -0.02  0.77  1.38  0.37  0.08  0.05 -0.11  0.05  0.33  0.13 -0.13\n",
      " -0.09]\n",
      "Episode:1 Score:0.24929859092364082\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.023900105326708, -0.38) reward:0.4039001005583364\n",
      "[ 0.77 -0.38  0.73  0.46  0.5   0.14  0.5   0.46  0.47  0.47  0.61  0.61\n",
      "  0.45  0.6   0.16  0.74  0.48  0.17 -0.14  0.49 -0.47  0.23  0.31  0.54\n",
      " -0.1   0.33  1.02  1.52  0.27  0.2   0.09 -0.35  0.18 -0.4   0.21  0.\n",
      " -0.09]\n",
      "Episode:1 Score:0.4039001005583364\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.3376934208218511, 0.04) reward:0.2976934217159208\n",
      "[ 0.78  0.04  0.78  0.43 -0.65 -0.17 -0.43  0.46  0.46  0.48  1.18  0.55\n",
      "  0.41  0.58  0.13  0.73  0.27 -0.03 -0.02  0.51  0.72  1.01  0.41  0.43\n",
      " -0.88  1.1  -0.01  0.71  0.41  0.17  0.03 -0.37 -0.14  0.96 -0.09  0.06\n",
      " -0.06]\n",
      "Episode:1 Score:0.2976934217159208\n",
      "init reached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loz/Documents/GitHub/MSc-Project/venv/lib/python3.12/site-packages/gym/spaces/box.py:127: UserWarning: \u001B[33mWARN: Box bound precision lowered by casting to float32\u001B[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0625447381024288, -0.25) reward:0.3125447381024288\n",
      "[ 0.75 -0.25  0.7   0.47  0.39  0.11  0.34  0.49  0.49  0.51  0.57  0.67\n",
      "  0.5   0.92  0.14  0.79  0.46  0.12 -0.11  0.54 -0.48  0.08  0.12  0.47\n",
      "  0.11  0.2   0.91  1.48  0.09  0.07  0.23 -0.1   0.18 -0.16  0.22 -0.02\n",
      " -0.12]\n",
      "Episode:1 Score:0.3125447381024288\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0434008440071163, -0.22) reward:0.2634008428150234\n",
      "[ 0.85 -0.22  0.82  0.44 -0.35 -0.21 -0.3   0.47  0.48  0.49  1.12  0.55\n",
      "  0.48  0.85  0.18  0.71  0.21  0.01 -0.14  0.59  0.29  0.68  0.53  0.35\n",
      " -0.41  0.91  0.16  1.1   0.52  0.19 -0.1  -0.3  -0.38  0.93 -0.31  0.14\n",
      " -0.01]\n",
      "Episode:1 Score:0.2634008428150234\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0694411080721093, -0.29) reward:0.359441099727459\n",
      "[ 0.76 -0.29  0.73  0.49  0.5   0.12  0.59  0.5   0.51  0.52  0.46  0.67\n",
      "  0.48  0.93  0.19  0.81  0.48  0.12 -0.11  0.53 -0.48  0.14  0.17  0.64\n",
      "  0.    0.22  1.09  1.65  0.13  0.16  0.18 -0.23  0.25 -0.46  0.29  0.01\n",
      " -0.06]\n",
      "Episode:1 Score:0.359441099727459\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.1048750483542588, -0.22) reward:0.3248750471621659\n",
      "[ 0.7  -0.22  0.72  0.47  0.42  0.07  0.32  0.49  0.49  0.5   0.55  0.59\n",
      "  0.48  1.04  0.1   0.72  0.32  0.09 -0.11  0.55 -0.63 -0.03  0.02  0.89\n",
      "  0.31  0.2   0.89  1.25  0.03 -0.04  0.48  0.01  0.47  0.42  0.54  0.02\n",
      " -0.08]\n",
      "Episode:1 Score:0.3248750471621659\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.874078694227509, 0.69) reward:0.18407869661169474\n",
      "[ 0.71  0.69  0.76  0.38  0.59  0.8   0.34  0.4   0.4   0.4   1.06  0.49\n",
      "  0.34  0.53  0.08  0.68  0.23 -0.04  0.04  0.39 -0.47  0.13  0.44  1.01\n",
      " -0.12  0.22  1.01  1.54  0.52  0.31 -0.01 -0.51  0.14 -0.1   0.21 -0.12\n",
      " -0.1 ]\n",
      "Episode:1 Score:0.18407869661169474\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.985850415475544, 0.61) reward:0.3758504011704292\n",
      "[ 0.14  0.61  0.11  0.44 -0.62 -0.35 -0.57  0.44  0.44  0.48  0.8   0.66\n",
      "  0.52  0.35  0.07  0.74 -0.21 -0.3  -0.06  0.66  0.69  0.94  0.21  0.16\n",
      " -1.04  0.93 -0.12  0.42  0.32  0.08  0.07 -0.   -0.02  1.11  0.05  0.02\n",
      " -0.01]\n",
      "Episode:1 Score:0.3758504011704292\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.3249703058654889, 0.05) reward:0.27497030512043086\n",
      "[ 0.76  0.05  0.76  0.43 -0.62 -0.21 -0.47  0.45  0.46  0.47  1.16  0.52\n",
      "  0.39  0.55  0.08  0.7   0.24 -0.04 -0.05  0.5   0.67  1.01  0.45  0.43\n",
      " -0.88  1.11 -0.05  0.73  0.47  0.23 -0.05 -0.32 -0.21  1.01 -0.16  0.07\n",
      " -0.09]\n",
      "Episode:1 Score:0.27497030512043086\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1083235362631951, -0.31) reward:0.4183235386473809\n",
      "[ 0.73 -0.31  0.76  0.41  0.52 -0.    0.42  0.43  0.45  0.45  0.4   0.67\n",
      "  0.51  1.02  0.25  0.83  0.21 -0.03 -0.05  0.56 -0.36  0.47  0.35  1.06\n",
      " -0.34  0.55  1.09  1.79  0.39  0.36 -0.06 -0.45 -0.   -0.57  0.04 -0.03\n",
      "  0.04]\n",
      "Episode:1 Score:0.4183235386473809\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "lit:(0.0649226922560788, -0.17) reward:0.23492269404421814\n",
      "[ 0.72 -0.17  0.75  0.46  0.36 -0.01  0.21  0.49  0.48  0.51  1.08  0.54\n",
      "  0.45  1.12  0.09  0.68  0.21  0.06 -0.13  0.54 -0.62 -0.21 -0.12  0.02\n",
      "  0.39  0.02  0.92  1.2  -0.11 -0.21  0.37  0.15  0.17  0.39  0.27 -0.01\n",
      " -0.14]\n",
      "Episode:1 Score:0.23492269404421814\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0932224671531827, -0.3) reward:0.3932224790741117\n",
      "[ 0.86 -0.3   0.84  0.41 -0.55 -0.08 -0.29  0.48  0.46  0.5   1.14  0.69\n",
      "  0.55  1.04  0.31  0.86  0.22 -0.12 -0.02  0.64  0.58  0.85  0.32  0.56\n",
      " -0.66  0.98  0.21  1.    0.32  0.12  0.12 -0.35 -0.13  0.71 -0.06  0.07\n",
      "  0.09]\n",
      "Episode:1 Score:0.3932224790741117\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0608798672707779, -0.31) reward:0.37087986965496367\n",
      "[ 0.84 -0.31  0.85  0.44 -0.62 -0.23 -0.37  0.47  0.46  0.49  1.17  0.5\n",
      "  0.41  0.69  0.1   0.68  0.23 -0.03 -0.07  0.53  0.62  1.04  0.34  0.51\n",
      " -0.84  1.19  0.01  0.65  0.35  0.13  0.08 -0.25 -0.1   1.09 -0.03  0.11\n",
      " -0.07]\n",
      "Episode:1 Score:0.37087986965496367\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9856123171360828, 0.69) reward:0.29561231952026856\n",
      "[ 0.1   0.69  0.04  0.5  -0.51 -0.37 -0.58  0.48  0.5   0.53  0.83  0.68\n",
      "  0.54  0.46  0.05  0.76 -0.17 -0.28 -0.08  0.67  0.51  0.7   0.45 -0.03\n",
      " -0.74  0.73 -0.07  0.8   0.53  0.18 -0.19 -0.08 -0.36  1.01 -0.29 -0.\n",
      " -0.03]\n",
      "Episode:1 Score:0.29561231952026856\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "lit:(0.5318668575896266, 0.33) reward:0.20186684447660475\n",
      "[ 0.74  0.33  0.64  0.6  -0.73 -0.31 -0.58  0.62  0.64  0.65  1.06  0.65\n",
      "  0.57  0.91 -0.05  0.73 -0.03 -0.04  0.13  0.63  0.79  0.86  0.64  0.4\n",
      " -0.84  0.97 -0.22  0.68  0.71  0.29 -0.27 -0.44 -0.33  1.02 -0.29 -0.28\n",
      " -0.24]\n",
      "Episode:1 Score:0.20186684447660475\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9922711946144942, 0.79) reward:0.20227117315682208\n",
      "[ 0.21  0.79  0.17  0.44  0.64 -0.02  0.47  0.44  0.45  0.48  0.37  0.74\n",
      "  0.54  0.61  0.09  0.8  -0.02 -0.2   0.11  0.61 -0.49 -0.27 -0.13  0.16\n",
      "  0.13 -0.29  1.05  1.38 -0.07 -0.03  0.22  0.13  0.29 -0.42  0.35 -0.1\n",
      " -0.09]\n",
      "Episode:1 Score:0.20227117315682208\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.7561236863317922, 0.54) reward:0.21612366487412005\n",
      "[ 0.72  0.54  0.62  0.56 -0.91 -0.23 -0.67  0.6   0.62  0.64  1.1   0.68\n",
      "  0.57  0.93 -0.04  0.76 -0.02 -0.1   0.22  0.61  1.04  0.94  0.41  0.2\n",
      " -1.09  0.94 -0.28  0.4   0.5   0.16 -0.1  -0.33 -0.16  1.03 -0.13 -0.33\n",
      " -0.23]\n",
      "Episode:1 Score:0.21612366487412005\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0979786783845784, -0.35) reward:0.44797867242411393\n",
      "[ 0.87 -0.35  0.86  0.42 -0.51 -0.13 -0.25  0.49  0.46  0.5   1.15  0.64\n",
      "  0.55  1.11  0.28  0.83  0.21 -0.09 -0.07  0.66  0.42  0.8   0.27  0.54\n",
      " -0.51  1.01  0.21  0.91  0.26  0.    0.21 -0.27 -0.07  0.92  0.02  0.11\n",
      "  0.08]\n",
      "Episode:1 Score:0.44797867242411393\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0600477347790486, -0.48) reward:0.5400477240502125\n",
      "[ 1.14 -0.48  1.03  0.87 -0.79  0.   -0.29  0.88  0.88  0.88  1.43  0.69\n",
      "  0.63  0.46  0.43  0.89  0.62  0.37  0.14  0.74  0.81  1.25  0.49  0.66\n",
      " -1.01  1.38 -0.05  0.8   0.5   0.19  0.08 -0.43 -0.19  1.21 -0.15  0.3\n",
      "  0.32]\n",
      "Episode:1 Score:0.5400477240502125\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.1384066253134885, -0.19) reward:0.32840662292930267\n",
      "[ 0.71 -0.19  0.7   0.44  0.4   0.06  0.28  0.47  0.48  0.49  0.48  0.7\n",
      "  0.52  1.07  0.18  0.82  0.32  0.04 -0.01  0.53 -0.36  0.28  0.32  1.06\n",
      " -0.13  0.36  0.92  1.59  0.33  0.28  0.07 -0.36  0.15 -0.32  0.18 -0.08\n",
      " -0.06]\n",
      "Episode:1 Score:0.32840662292930267\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0751488038890606, -0.15) reward:0.22514880984952507\n",
      "[ 0.74 -0.15  0.75  0.4   0.17 -0.09 -0.08  0.44  0.45  0.46  1.05  0.54\n",
      "  0.45  0.95  0.21  0.69  0.17  0.02 -0.18  0.53 -0.38  0.21  0.51  0.43\n",
      "  0.07  0.49  0.57  1.5   0.53  0.23 -0.08 -0.32 -0.34  0.49 -0.26  0.01\n",
      " -0.01]\n",
      "Episode:1 Score:0.22514880984952507\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.5926279786147706, 0.36) reward:0.23262796430965582\n",
      "[ 0.68  0.36  0.62  0.59  0.5   1.01  0.55  0.58  0.59  0.58  0.66  0.49\n",
      "  0.47  1.1  -0.14  0.59  0.12  0.09  0.22  0.55 -0.65 -0.34  0.03  0.77\n",
      "  0.48 -0.11  0.73  0.92  0.13 -0.07  0.39 -0.05  0.61  0.46  0.67 -0.27\n",
      " -0.29]\n",
      "Episode:1 Score:0.23262796430965582\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.986325703382178, 1.08) reward:0.09367433953316628\n",
      "[ 0.4   1.08  0.45  0.39  0.62  0.17  0.3   0.4   0.41  0.41  1.07  0.45\n",
      "  0.32  0.42  0.05  0.57  0.19  0.09 -0.09  0.37 -0.59 -0.18  0.19  0.23\n",
      "  0.03 -0.12  0.99  1.28  0.26  0.08  0.13 -0.24  0.22 -0.04  0.27 -0.13\n",
      " -0.15]\n",
      "Episode:1 Score:0.09367433953316628\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.122473423711747, -0.13) reward:0.25247341894337544\n",
      "[ 0.83 -0.13  0.81  0.43 -0.41 -0.16 -0.32  0.48  0.47  0.5   1.13  0.63\n",
      "  0.54  1.13  0.21  0.79  0.16 -0.09 -0.09  0.64  0.34  0.68  0.48  0.51\n",
      " -0.42  0.89  0.19  1.17  0.48  0.18 -0.05 -0.34 -0.32  0.82 -0.25  0.07\n",
      "  0.02]\n",
      "Episode:1 Score:0.25247341894337544\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0536266527160023, -0.43) reward:0.4836266598685597\n",
      "[ 0.89 -0.43  0.86  0.41 -0.6  -0.14 -0.32  0.47  0.46  0.49  1.15  0.65\n",
      "  0.51  0.8   0.29  0.82  0.26 -0.04 -0.03  0.61  0.63  0.91  0.24  0.5\n",
      " -0.73  1.05  0.13  0.72  0.23  0.03  0.18 -0.25 -0.11  0.91 -0.04  0.15\n",
      "  0.09]\n",
      "Episode:1 Score:0.4836266598685597\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.9673008584565956, 0.79) reward:0.17730083699892352\n",
      "[ 0.56  0.79  0.47  0.48 -0.88 -0.18 -0.66  0.51  0.54  0.55  1.03  0.65\n",
      "  0.56  0.96 -0.04  0.73 -0.05 -0.12  0.18  0.62  0.99  0.87  0.38 -0.03\n",
      " -1.09  0.85 -0.32  0.35  0.51  0.15 -0.11 -0.31 -0.16  1.03 -0.13 -0.33\n",
      " -0.24]\n",
      "Episode:1 Score:0.17730083699892352\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.9875149833830988, 0.62) reward:0.36751497861472726\n",
      "[ 0.06  0.62  0.01  0.42 -0.63 -0.39 -0.61  0.41  0.42  0.46  0.75  0.68\n",
      "  0.55  0.56  0.07  0.75 -0.22 -0.32 -0.1   0.68  0.64  0.91  0.22  0.05\n",
      " -1.    0.89 -0.15  0.52  0.33  0.09 -0.03  0.09 -0.2   1.09 -0.13  0.02\n",
      "  0.01]\n",
      "Episode:1 Score:0.36751497861472726\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0369797619440699, -0.39) reward:0.42697974763895513\n",
      "[ 0.87 -0.39  0.85  0.43 -0.63 -0.21 -0.4   0.46  0.47  0.49  1.14  0.59\n",
      "  0.47  0.72  0.19  0.75  0.25 -0.02 -0.09  0.57  0.67  0.99  0.34  0.43\n",
      " -0.85  1.1   0.05  0.72  0.35  0.13  0.02 -0.24 -0.23  0.95 -0.17  0.14\n",
      "  0.02]\n",
      "Episode:1 Score:0.42697974763895513\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9870393925523688, 0.66) reward:0.32703936632632513\n",
      "[ 0.1   0.66  0.1   0.46  0.55 -0.02  0.29  0.47  0.46  0.5   0.42  0.71\n",
      "  0.56  0.98  0.08  0.82 -0.01 -0.2  -0.    0.67 -0.7  -0.43 -0.22  0.16\n",
      "  0.44 -0.3   0.95  1.14 -0.14 -0.2   0.48  0.24  0.52  0.27  0.61 -0.06\n",
      " -0.07]\n",
      "Episode:1 Score:0.32703936632632513\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0500594185614315, -0.37) reward:0.42005942332980306\n",
      "[ 0.75 -0.37  0.73  0.47  0.43  0.05  0.22  0.48  0.47  0.49  0.71  0.54\n",
      "  0.45  0.76  0.12  0.67  0.47  0.17 -0.19  0.53 -0.71  0.02  0.14  0.86\n",
      "  0.36  0.32  0.85  1.18  0.11 -0.05  0.5  -0.06  0.46  0.67  0.55  0.13\n",
      " -0.05]\n",
      "Episode:1 Score:0.42005942332980306\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.8960761333072014, 0.78) reward:0.11607616191743086\n",
      "[ 0.65  0.78  0.69  0.41  0.47  0.01 -0.12  0.44  0.45  0.45  1.03  0.48\n",
      "  0.38  0.8   0.09  0.59  0.15  0.08 -0.14  0.43 -0.74 -0.09  0.35  0.69\n",
      "  0.24  0.16  0.71  1.4   0.43  0.1   0.12 -0.13  0.03  0.56  0.1  -0.08\n",
      " -0.07]\n",
      "Episode:1 Score:0.11607616191743086\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1581451594092615, -0.05) reward:0.20814516015431955\n",
      "[ 0.7  -0.05  0.62  0.55  0.56 -0.08  0.54  0.55  0.57  0.56  0.2   0.64\n",
      "  0.51  0.99 -0.02  0.68  0.11  0.06  0.27  0.51 -0.42 -0.08  0.22  1.1\n",
      "  0.1   0.03  0.9   1.26  0.27  0.15  0.09 -0.35  0.46 -0.43  0.47 -0.28\n",
      " -0.24]\n",
      "Episode:1 Score:0.20814516015431955\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0957194704765633, -0.3) reward:0.3957194823974923\n",
      "[ 0.75 -0.3   0.76  0.42  0.57 -0.    0.47  0.44  0.46  0.46  0.32  0.66\n",
      "  0.5   1.01  0.23  0.81  0.19 -0.   -0.05  0.55 -0.39  0.47  0.28  0.97\n",
      " -0.34  0.55  1.11  1.83  0.32  0.32 -0.06 -0.33 -0.04 -0.61  0.   -0.04\n",
      "  0.02]\n",
      "Episode:1 Score:0.3957194823974923\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1355530803291087, -0.33) reward:0.4655530934421306\n",
      "[ 0.85 -0.33  0.85  0.39 -0.53 -0.13 -0.26  0.47  0.44  0.48  1.14  0.65\n",
      "  0.55  1.17  0.26  0.84  0.2  -0.13 -0.01  0.65  0.45  0.85  0.35  0.83\n",
      " -0.56  1.05  0.15  0.89  0.35  0.09  0.17 -0.38 -0.04  0.86  0.05  0.07\n",
      "  0.06]\n",
      "Episode:1 Score:0.4655530934421306\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.99512504252297, 0.61) reward:0.3851250282178552\n",
      "[ 0.12  0.61  0.1   0.47  0.58  0.7   0.71  0.46  0.46  0.49  0.5   0.64\n",
      "  0.53  0.91  0.01  0.81 -0.06 -0.18  0.04  0.7  -0.77 -0.36 -0.13  0.2\n",
      "  0.51 -0.2   0.84  1.19 -0.05 -0.1   0.34  0.29  0.3   0.3   0.39 -0.1\n",
      " -0.13]\n",
      "Episode:1 Score:0.3851250282178552\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1095125133400198, -0.15) reward:0.25951251930048425\n",
      "[ 0.73 -0.15  0.75  0.4   0.23 -0.06 -0.12  0.45  0.44  0.46  1.05  0.55\n",
      "  0.47  1.02  0.2   0.7   0.18  0.01 -0.17  0.54 -0.49  0.14  0.47  0.64\n",
      "  0.15  0.42  0.61  1.44  0.49  0.18 -0.02 -0.32 -0.23  0.49 -0.15  0.01\n",
      " -0.02]\n",
      "Episode:1 Score:0.25951251930048425\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.8562425234546553, 0.66) reward:0.19624249722861165\n",
      "[ 0.7   0.66  0.6   0.54 -0.94 -0.23 -0.71  0.58  0.6   0.61  1.1   0.67\n",
      "  0.57  0.93 -0.03  0.75  0.   -0.08  0.2   0.62  1.05  0.95  0.43  0.08\n",
      " -1.12  0.94 -0.31  0.39  0.53  0.14 -0.13 -0.34 -0.19  1.06 -0.15 -0.32\n",
      " -0.22]\n",
      "Episode:1 Score:0.19624249722861165\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1963142013542527, -0.0) reward:0.1963142013542527\n",
      "[ 0.65 -0.    0.64  0.44  0.54  0.06  0.47  0.44  0.46  0.46  0.59  0.61\n",
      "  0.44  0.6   0.15  0.75  0.32  0.08 -0.06  0.49 -0.41  0.28  0.24  0.64\n",
      " -0.16  0.35  1.05  1.63  0.22  0.2   0.07 -0.3   0.1  -0.46  0.14 -0.02\n",
      " -0.09]\n",
      "Episode:1 Score:0.1963142013542527\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.172889383934178, -0.06) reward:0.23288938259307349\n",
      "[ 0.64 -0.06  0.62  0.6   0.5  -0.07  0.24  0.61  0.61  0.61  0.41  0.58\n",
      "  0.51  0.95 -0.03  0.6   0.08  0.07  0.14  0.53 -0.6  -0.24  0.01  1.19\n",
      "  0.35 -0.03  0.84  0.91  0.08 -0.07  0.45 -0.12  0.74  0.3   0.79 -0.19\n",
      " -0.16]\n",
      "Episode:1 Score:0.23288938259307349\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.3868013547977271, 0.11) reward:0.27680135539377354\n",
      "[ 0.75  0.11  0.76  0.43 -0.6  -0.25 -0.48  0.44  0.46  0.47  1.16  0.47\n",
      "  0.37  0.53  0.04  0.65  0.22 -0.01 -0.09  0.49  0.63  1.05  0.43  0.39\n",
      " -0.91  1.16 -0.09  0.62  0.47  0.21 -0.06 -0.27 -0.22  1.1  -0.16  0.07\n",
      " -0.12]\n",
      "Episode:1 Score:0.27680135539377354\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.030915524466119, -0.1) reward:0.13091552595623512\n",
      "[ 0.78 -0.1   0.68  0.73  0.47 -0.09  0.44  0.72  0.73  0.71  0.56  0.61\n",
      "  0.52  0.62  0.14  0.64  0.48  0.22 -0.04  0.49 -0.41  0.3   0.48  1.02\n",
      " -0.13  0.41  0.87  1.65  0.47  0.3   0.   -0.53  0.19 -0.33  0.2  -0.06\n",
      " -0.06]\n",
      "Episode:1 Score:0.13091552595623512\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0240191544964385, -0.41) reward:0.4340191509201598\n",
      "[ 0.88 -0.41  0.85  0.43 -0.62 -0.2  -0.38  0.46  0.47  0.49  1.14  0.58\n",
      "  0.46  0.68  0.2   0.75  0.27 -0.   -0.11  0.57  0.65  0.98  0.34  0.36\n",
      " -0.84  1.1   0.06  0.73  0.35  0.12  0.03 -0.23 -0.23  0.96 -0.16  0.16\n",
      "  0.02]\n",
      "Episode:1 Score:0.4340191509201598\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9850179800597184, 0.63) reward:0.35501798482809\n",
      "[ 0.21  0.63  0.19  0.43 -0.62 -0.36 -0.6   0.42  0.42  0.45  0.79  0.63\n",
      "  0.49  0.16  0.04  0.71 -0.18 -0.26 -0.06  0.63  0.71  1.02  0.27  0.23\n",
      " -1.11  1.   -0.16  0.4   0.38  0.15  0.04 -0.04 -0.02  1.14  0.04  0.03\n",
      " -0.03]\n",
      "Episode:1 Score:0.35501798482809\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.99512504252297, 0.67) reward:0.3251250258336694\n",
      "[ 0.    0.67 -0.06  0.45  0.57  0.64  0.64  0.44  0.43  0.46  0.42  0.55\n",
      "  0.52  1.04 -0.01  0.61 -0.22  0.01  0.04  0.68 -0.76 -0.35 -0.08  0.26\n",
      "  0.5  -0.18  0.73  1.16  0.01 -0.09  0.28  0.22  0.22  0.34  0.31 -0.21\n",
      " -0.17]\n",
      "Episode:1 Score:0.3251250258336694\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0607611210251435, -0.16) reward:0.2207611174488648\n",
      "[ 0.68 -0.16  0.7   0.4   0.37  0.02  0.21  0.42  0.43  0.45  0.7   0.58\n",
      "  0.5   1.13  0.03  0.69  0.12  0.05 -0.22  0.59 -0.63 -0.09 -0.07  0.04\n",
      "  0.36  0.16  0.72  1.17 -0.06 -0.21  0.34  0.18  0.13  0.45  0.21 -0.07\n",
      " -0.22]\n",
      "Episode:1 Score:0.2207611174488648\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0756243947197907, -0.31) reward:0.3856243971039765\n",
      "[ 0.76 -0.31  0.81  0.46  0.45  1.11  0.43  0.5   0.48  0.52  1.1   0.57\n",
      "  0.47  1.11  0.15  0.74  0.25 -0.02 -0.1   0.59 -0.66 -0.23 -0.16  0.6\n",
      "  0.43 -0.03  1.    1.2  -0.13 -0.21  0.5   0.14  0.48  0.33  0.57  0.06\n",
      " -0.03]\n",
      "Episode:1 Score:0.3856243971039765\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0839478401057567, -0.34) reward:0.4239478436820354\n",
      "[ 0.87 -0.34  0.85  0.42 -0.46 -0.11 -0.2   0.49  0.46  0.5   1.14  0.64\n",
      "  0.55  1.09  0.3   0.83  0.22 -0.09 -0.07  0.66  0.38  0.76  0.27  0.51\n",
      " -0.47  0.97  0.26  0.99  0.26  0.03  0.23 -0.28 -0.04  0.86  0.04  0.11\n",
      "  0.09]\n",
      "Episode:1 Score:0.4239478436820354\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1068964608469089, -0.29) reward:0.39689645250225863\n",
      "[ 0.73 -0.29  0.75  0.41  0.51  0.    0.39  0.44  0.45  0.45  0.44  0.67\n",
      "  0.52  1.02  0.25  0.83  0.2  -0.02 -0.06  0.56 -0.37  0.46  0.35  1.06\n",
      " -0.32  0.55  1.05  1.79  0.39  0.34 -0.06 -0.43 -0.02 -0.52  0.03 -0.04\n",
      "  0.04]\n",
      "Episode:1 Score:0.39689645250225863\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.14803809694601, -0.06) reward:0.2080380956049055\n",
      "[ 0.86 -0.06  0.81  0.6  -0.65 -0.16 -0.29  0.66  0.65  0.65  1.35  0.64\n",
      "  0.56  1.01  0.14  0.76  0.21 -0.06  0.07  0.59  0.65  0.9   0.57  0.88\n",
      " -0.76  1.05 -0.09  0.8   0.6   0.27 -0.1  -0.58 -0.24  0.83 -0.2  -0.09\n",
      " -0.05]\n",
      "Episode:1 Score:0.2080380956049055\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.845422074745309, 0.76) reward:0.08542208428205211\n",
      "[ 0.63  0.76  0.54  0.54  0.46  0.1   0.13  0.53  0.56  0.56  0.56  0.62\n",
      "  0.51  0.99 -0.08  0.64  0.17  0.1   0.18  0.52 -0.47 -0.39  0.01  0.33\n",
      "  0.25 -0.32  0.82  1.07  0.1  -0.07  0.3  -0.1   0.59 -0.03  0.61 -0.35\n",
      " -0.31]\n",
      "Episode:1 Score:0.08542208428205211\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0227111282498833, -0.39) reward:0.41271111394476856\n",
      "[ 0.78 -0.39  0.75  0.44  0.48  0.06  0.4   0.45  0.46  0.47  0.65  0.61\n",
      "  0.45  0.59  0.21  0.75  0.43  0.14 -0.17  0.5  -0.46  0.27  0.25  0.52\n",
      " -0.13  0.36  1.03  1.55  0.22  0.16  0.11 -0.29  0.11 -0.37  0.15  0.04\n",
      " -0.02]\n",
      "Episode:1 Score:0.41271111394476856\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.1485136877767401, -0.27) reward:0.4185136985055762\n",
      "[ 0.83 -0.27  0.83  0.39 -0.5  -0.14 -0.29  0.46  0.44  0.47  1.13  0.62\n",
      "  0.53  1.12  0.22  0.8   0.17 -0.13 -0.03  0.62  0.46  0.9   0.41  0.85\n",
      " -0.64  1.08  0.13  0.92  0.43  0.19  0.07 -0.39 -0.13  0.82 -0.05  0.06\n",
      "  0.04]\n",
      "Episode:1 Score:0.4185136985055762\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.987752778798464, 0.59) reward:0.3977528050245077\n",
      "[ 0.12  0.59  0.09  0.5  -0.68 -0.31 -0.58  0.52  0.52  0.57  0.87  0.75\n",
      "  0.56  0.55  0.12  0.84 -0.16 -0.38  0.02  0.68  0.79  0.82  0.21  0.07\n",
      " -1.01  0.76 -0.05  0.47  0.31  0.1   0.03 -0.09 -0.03  0.9   0.03 -0.02\n",
      " -0.  ]\n",
      "Episode:1 Score:0.3977528050245077\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0386446327757208, -0.21) reward:0.24864462621920988\n",
      "[ 0.71 -0.21  0.71  0.43  0.4   0.03  0.25  0.45  0.45  0.47  0.72  0.55\n",
      "  0.47  0.95  0.03  0.67  0.22  0.11 -0.21  0.56 -0.67 -0.01  0.06  0.29\n",
      "  0.33  0.27  0.71  1.18  0.06 -0.09  0.31  0.08  0.13  0.51  0.2  -0.02\n",
      " -0.19]\n",
      "Episode:1 Score:0.24864462621920988\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.5869205857219153, 0.32) reward:0.2669205928744727\n",
      "[ 0.72  0.32  0.72  0.44  0.66  1.08  0.67  0.45  0.45  0.44  0.79  0.58\n",
      "  0.41  0.51  0.1   0.76  0.33  0.01  0.09  0.47 -0.38  0.39  0.5   1.36\n",
      " -0.28  0.41  1.16  1.81  0.53  0.39 -0.05 -0.61  0.23 -0.54  0.28 -0.07\n",
      " -0.08]\n",
      "Episode:1 Score:0.2669205928744727\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.2931035997379101, 0.13) reward:0.1631036045062817\n",
      "[ 0.6   0.13  0.57  0.45  0.56  0.11  0.58  0.45  0.46  0.46  0.48  0.59\n",
      "  0.41  0.58  0.09  0.72  0.35  0.11 -0.04  0.47 -0.44  0.18  0.24  0.61\n",
      " -0.09  0.25  1.    1.5   0.24  0.22  0.11 -0.27  0.22 -0.38  0.25 -0.05\n",
      " -0.15]\n",
      "Episode:1 Score:0.1631036045062817\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.8980975457998512, 0.58) reward:0.3180975624891518\n",
      "[ 0.84  0.58  0.7   0.63  0.45  0.01  0.13  0.61  0.61  0.6   0.69  0.65\n",
      "  0.46  0.24  0.1   0.76  0.85  0.26  0.18  0.42 -0.38  0.3   0.71  1.27\n",
      " -0.16  0.42  0.91  1.65  0.73  0.35 -0.01 -0.77  0.24  0.01  0.27 -0.11\n",
      " -0.03]\n",
      "Episode:1 Score:0.3180975624891518\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.1170035233101605, -0.11) reward:0.22700352271411406\n",
      "[ 0.74 -0.11  0.76  0.4   0.24 -0.06 -0.12  0.45  0.44  0.46  1.05  0.54\n",
      "  0.47  1.04  0.19  0.68  0.15  0.01 -0.17  0.54 -0.5   0.14  0.44  0.68\n",
      "  0.16  0.42  0.58  1.45  0.47  0.17 -0.02 -0.26 -0.26  0.5  -0.18  0.\n",
      " -0.02]\n",
      "Episode:1 Score:0.22700352271411406\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0495838277307016, -0.21) reward:0.25958382117419065\n",
      "[ 0.71 -0.21  0.71  0.43  0.4   0.03  0.25  0.45  0.45  0.47  0.72  0.55\n",
      "  0.47  0.95  0.03  0.67  0.22  0.11 -0.22  0.56 -0.67 -0.01  0.05  0.27\n",
      "  0.32  0.27  0.71  1.18  0.05 -0.1   0.31  0.09  0.12  0.5   0.2  -0.02\n",
      " -0.19]\n",
      "Episode:1 Score:0.25958382117419065\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.142211654883424, -0.26) reward:0.40221164534668086\n",
      "[ 0.85 -0.26  0.84  0.4  -0.56 -0.14 -0.35  0.46  0.44  0.48  1.14  0.66\n",
      "  0.54  1.12  0.22  0.83  0.18 -0.14 -0.01  0.62  0.55  0.9   0.41  0.85\n",
      " -0.68  1.05  0.11  0.94  0.42  0.2   0.04 -0.38 -0.17  0.78 -0.1   0.04\n",
      "  0.03]\n",
      "Episode:1 Score:0.40221164534668086\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.1372176482366636, -0.25) reward:0.3872176482366636\n",
      "[ 0.73 -0.25  0.74  0.43  0.42  1.13  0.51  0.47  0.46  0.49  0.7   0.72\n",
      "  0.55  1.2   0.15  0.9   0.32 -0.01  0.01  0.61 -0.44  0.17  0.25  1.13\n",
      "  0.03  0.24  0.9   1.55  0.26  0.21  0.12 -0.29  0.23 -0.3   0.27 -0.06\n",
      " -0.09]\n",
      "Episode:1 Score:0.3872176482366636\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.4000000605848191, 0.27) reward:0.130000049855983\n",
      "[ 0.69  0.27  0.58  0.52  0.51  0.    0.32  0.51  0.56  0.55  0.35  0.63\n",
      "  0.54  1.05 -0.    0.68  0.15  0.08  0.15  0.57 -0.36 -0.01  0.17  0.18\n",
      " -0.07  0.04  0.94  1.48  0.25  0.14  0.   -0.25  0.2  -0.49  0.22 -0.29\n",
      " -0.23]\n",
      "Episode:1 Score:0.130000049855983\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.111296130417305, -0.23) reward:0.34129613458963015\n",
      "[ 0.73 -0.23  0.72  0.43  0.43  0.02  0.28  0.46  0.47  0.48  0.54  0.68\n",
      "  0.52  1.02  0.23  0.81  0.31  0.03 -0.08  0.55 -0.38  0.32  0.32  0.97\n",
      " -0.17  0.4   0.98  1.74  0.32  0.3   0.03 -0.34  0.07 -0.42  0.11 -0.02\n",
      "  0.  ]\n",
      "Episode:1 Score:0.34129613458963015\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0980977275543089, -0.34) reward:0.4380977311305876\n",
      "[ 0.88 -0.34  0.86  0.42 -0.56 -0.06 -0.26  0.5   0.47  0.51  1.16  0.71\n",
      "  0.56  1.05  0.35  0.9   0.26 -0.11  0.    0.64  0.59  0.8   0.26  0.51\n",
      " -0.6   0.94  0.26  0.96  0.24  0.05  0.2  -0.35 -0.07  0.72  0.    0.09\n",
      "  0.12]\n",
      "Episode:1 Score:0.4380977311305876\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0909632592451676, -0.32) reward:0.4109632520926102\n",
      "[ 0.89 -0.32  0.87  0.42 -0.54 -0.06 -0.26  0.5   0.48  0.51  1.16  0.7\n",
      "  0.55  1.03  0.33  0.88  0.25 -0.1   0.    0.63  0.59  0.79  0.21  0.42\n",
      " -0.61  0.93  0.28  0.94  0.19  0.03  0.2  -0.27 -0.12  0.73 -0.04  0.09\n",
      "  0.11]\n",
      "Episode:1 Score:0.4109632520926102\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0561236560393825, -0.25) reward:0.3061236560393825\n",
      "[ 0.83 -0.25  0.81  0.46 -0.52 -0.12 -0.25  0.49  0.48  0.5   1.15  0.62\n",
      "  0.54  0.78  0.21  0.76  0.21 -0.04 -0.17  0.65  0.5   0.89  0.47  0.51\n",
      " -0.71  1.03  0.01  0.88  0.48  0.18 -0.03 -0.36 -0.21  0.88 -0.15  0.11\n",
      "  0.04]\n",
      "Episode:1 Score:0.3061236560393825\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0524376756391773, -0.39) reward:0.44243766133406254\n",
      "[ 0.75 -0.39  0.76  0.44  0.59  0.    0.41  0.45  0.47  0.47  0.46  0.62\n",
      "  0.47  0.83  0.24  0.78  0.29  0.06 -0.14  0.52 -0.43  0.47  0.31  0.6\n",
      " -0.37  0.54  1.21  1.83  0.34  0.32 -0.09 -0.36 -0.08 -0.63 -0.04  0.01\n",
      "  0.04]\n",
      "Episode:1 Score:0.44243766133406254\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1438765257150751, -0.27) reward:0.41387653644391115\n",
      "[ 0.86 -0.27  0.84  0.42 -0.58 -0.09 -0.33  0.49  0.47  0.5   1.16  0.69\n",
      "  0.56  1.07  0.28  0.86  0.22 -0.12 -0.01  0.64  0.59  0.85  0.33  0.63\n",
      " -0.65  0.99  0.16  0.93  0.32  0.12  0.12 -0.35 -0.13  0.77 -0.06  0.07\n",
      "  0.07]\n",
      "Episode:1 Score:0.41387653644391115\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.132699232420633, -0.13) reward:0.2626992276522614\n",
      "[ 0.82 -0.13  0.81  0.42 -0.43 -0.18 -0.34  0.47  0.46  0.49  1.13  0.63\n",
      "  0.54  1.15  0.19  0.79  0.16 -0.1  -0.08  0.63  0.36  0.7   0.54  0.63\n",
      " -0.42  0.9   0.16  1.17  0.54  0.24 -0.08 -0.39 -0.32  0.83 -0.24  0.06\n",
      "  0.  ]\n",
      "Episode:1 Score:0.2626992276522614\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.9940548116917796, 0.79) reward:0.20405479023410744\n",
      "[ 0.18  0.79  0.14  0.44  0.62 -0.02  0.46  0.44  0.45  0.48  0.37  0.74\n",
      "  0.55  0.72  0.1   0.82 -0.03 -0.21  0.1   0.62 -0.51 -0.28 -0.09  0.11\n",
      "  0.15 -0.29  1.02  1.4  -0.02  0.    0.19  0.11  0.25 -0.37  0.31 -0.1\n",
      " -0.08]\n",
      "Episode:1 Score:0.20405479023410744\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.2129607892020888, 0.07) reward:0.14296078890406558\n",
      "[ 0.62  0.07  0.61  0.45  0.48  0.09  0.34  0.46  0.46  0.47  0.64  0.61\n",
      "  0.45  0.64  0.07  0.72  0.29  0.08 -0.03  0.5  -0.48  0.06  0.11  0.56\n",
      "  0.07  0.15  0.98  1.46  0.1   0.1   0.2  -0.12  0.23 -0.2   0.28 -0.05\n",
      " -0.17]\n",
      "Episode:1 Score:0.14296078890406558\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1155767508179705, -0.29) reward:0.4055767424733202\n",
      "[ 0.69 -0.29  0.77  0.43  0.45  0.73  0.17  0.48  0.45  0.48  1.06  0.55\n",
      "  0.49  1.22  0.13  0.71  0.22 -0.03 -0.12  0.59 -0.78 -0.21 -0.03  1.05\n",
      "  0.49  0.05  0.9   1.14  0.01 -0.19  0.52  0.02  0.57  0.62  0.67  0.06\n",
      " -0.02]\n",
      "Episode:1 Score:0.4055767424733202\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0875147713362314, -0.13) reward:0.2175147665678598\n",
      "[ 0.75 -0.13  0.75  0.39  0.17 -0.08 -0.1   0.44  0.44  0.45  1.04  0.53\n",
      "  0.45  0.97  0.21  0.68  0.14  0.01 -0.18  0.53 -0.37  0.25  0.49  0.49\n",
      "  0.03  0.53  0.54  1.48  0.52  0.26 -0.09 -0.29 -0.39  0.49 -0.31 -0.\n",
      " -0.  ]\n",
      "Episode:1 Score:0.2175147665678598\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.4177171821879419, 0.34) reward:0.07771717861166322\n",
      "[ 0.53  0.34  0.57  0.44  0.6   0.05  0.59  0.43  0.44  0.45  0.54  0.45\n",
      "  0.37  0.63 -0.07  0.58  0.14  0.08 -0.09  0.48 -0.77 -0.18 -0.06  0.5\n",
      "  0.4   0.07  0.86  1.1  -0.02 -0.07  0.45  0.18  0.43  0.51  0.51 -0.02\n",
      " -0.23]\n",
      "Episode:1 Score:0.07771717861166322\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.1428062948838846, -0.26) reward:0.40280628534714147\n",
      "[ 0.84 -0.26  0.83  0.4  -0.53 -0.14 -0.34  0.47  0.45  0.48  1.14  0.64\n",
      "  0.54  1.11  0.21  0.81  0.17 -0.12 -0.04  0.63  0.5   0.88  0.39  0.77\n",
      " -0.64  1.05  0.12  0.96  0.4   0.16  0.04 -0.34 -0.2   0.81 -0.12  0.05\n",
      "  0.03]\n",
      "Episode:1 Score:0.40280628534714147\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "lit:(0.8866824570900447, 0.76) reward:0.12668246662678784\n",
      "[ 0.63  0.76  0.68  0.42  0.49  0.04 -0.1   0.44  0.45  0.46  1.02  0.47\n",
      "  0.37  0.74  0.08  0.59  0.18  0.09 -0.15  0.42 -0.76 -0.11  0.35  0.66\n",
      "  0.24  0.12  0.75  1.37  0.43  0.13  0.15 -0.15  0.12  0.53  0.19 -0.07\n",
      " -0.09]\n",
      "Episode:1 Score:0.12668246662678784\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.1291319982660626, -0.19) reward:0.3191319958818768\n",
      "[ 0.69 -0.19  0.71  0.45  0.38  0.05  0.16  0.48  0.47  0.49  0.59  0.61\n",
      "  0.5   1.12  0.1   0.72  0.28  0.05 -0.1   0.56 -0.62 -0.05  0.    1.08\n",
      "  0.34  0.17  0.86  1.24  0.01 -0.06  0.48  0.03  0.46  0.41  0.54  0.01\n",
      " -0.06]\n",
      "Episode:1 Score:0.3191319958818768\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.9869203433826386, 0.64) reward:0.3469203576877533\n",
      "[ 0.23  0.64  0.22  0.46 -0.55 -0.33 -0.55  0.44  0.45  0.47  0.83  0.62\n",
      "  0.49  0.16  0.03  0.71 -0.14 -0.24 -0.06  0.63  0.63  0.95  0.4   0.23\n",
      " -1.    0.96 -0.12  0.51  0.49  0.2  -0.03 -0.18 -0.03  1.08  0.03  0.02\n",
      " -0.05]\n",
      "Episode:1 Score:0.3469203576877533\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0422115640061955, -0.16) reward:0.2022115604299168\n",
      "[ 1.01 -0.16  0.91  0.98  0.46  0.27  0.7   0.93  0.94  0.89  0.94  0.48\n",
      "  0.41  0.28  0.43  0.72  1.22  0.46  0.04  0.5  -0.41  0.43  0.63  1.06\n",
      " -0.06  0.64  1.08  1.99  0.6   0.45 -0.01 -0.74  0.09 -0.02  0.13  0.64\n",
      "  0.42]\n",
      "Episode:1 Score:0.2022115604299168\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.2020215942471079, -0.03) reward:0.23202159357655563\n",
      "[ 0.65 -0.03  0.63  0.46  0.54  0.13  0.57  0.46  0.47  0.47  0.47  0.61\n",
      "  0.43  0.61  0.1   0.75  0.41  0.12 -0.03  0.47 -0.43  0.23  0.36  0.72\n",
      " -0.11  0.32  1.03  1.57  0.34  0.3   0.07 -0.43  0.25 -0.4   0.28 -0.05\n",
      " -0.14]\n",
      "Episode:1 Score:0.23202159357655563\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.7656364117186791, 0.62) reward:0.14563640695030755\n",
      "[ 0.61  0.62  0.67  0.42  0.59  0.96  0.51  0.43  0.44  0.45  1.09  0.41\n",
      "  0.32  0.68 -0.06  0.59  0.21  0.04 -0.06  0.43 -0.79 -0.34 -0.15  0.34\n",
      "  0.47 -0.12  0.89  0.95 -0.08 -0.18  0.52  0.21  0.49  0.62  0.57 -0.06\n",
      " -0.24]\n",
      "Episode:1 Score:0.14563640695030755\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.6554102092084688, 0.41) reward:0.2454102127847475\n",
      "[ 0.73  0.41  0.64  0.56 -0.92 -0.23 -0.63  0.61  0.62  0.64  1.09  0.69\n",
      "  0.58  0.93 -0.01  0.78 -0.   -0.1   0.22  0.63  1.04  0.97  0.44  0.3\n",
      " -1.08  0.98 -0.28  0.38  0.53  0.17 -0.09 -0.4  -0.11  1.02 -0.08 -0.29\n",
      " -0.21]\n",
      "Episode:1 Score:0.2454102127847475\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0287753657278342, -0.45) reward:0.4787753538069052\n",
      "[ 0.89 -0.45  0.85  0.42 -0.63 -0.17 -0.36  0.47  0.47  0.5   1.15  0.62\n",
      "  0.49  0.74  0.25  0.79  0.28 -0.01 -0.08  0.59  0.66  0.95  0.26  0.39\n",
      " -0.79  1.07  0.09  0.67  0.26  0.06  0.11 -0.21 -0.18  0.95 -0.11  0.17\n",
      "  0.06]\n",
      "Episode:1 Score:0.4787753538069052\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.051367444807987, -0.44) reward:0.4913674424238012\n",
      "[ 0.89 -0.44  0.86  0.42 -0.62 -0.16 -0.35  0.47  0.46  0.5   1.15  0.63\n",
      "  0.5   0.78  0.26  0.8   0.27 -0.03 -0.05  0.6   0.64  0.94  0.3   0.51\n",
      " -0.76  1.08  0.1   0.71  0.29  0.08  0.14 -0.28 -0.12  0.94 -0.05  0.16\n",
      "  0.07]\n",
      "Episode:1 Score:0.4913674424238012\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9917956037837644, 0.76) reward:0.23179561332050758\n",
      "[ 0.23  0.76  0.2   0.37  0.66 -0.03  0.37  0.37  0.39  0.41  0.29  0.74\n",
      "  0.55  0.7   0.15  0.83 -0.06 -0.22  0.04  0.62 -0.36  0.1   0.15  0.19\n",
      " -0.25  0.08  1.05  1.61  0.26  0.22 -0.06 -0.17  0.02 -0.58  0.08 -0.12\n",
      " -0.01]\n",
      "Episode:1 Score:0.23179561332050758\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1082047900175604, -0.33) reward:0.43820480313058224\n",
      "[ 0.79 -0.33  0.8   0.47  0.38  1.27  0.52  0.52  0.51  0.54  1.06  0.68\n",
      "  0.51  1.16  0.23  0.91  0.43 -0.03 -0.01  0.6  -0.56 -0.06  0.1   0.83\n",
      "  0.29  0.08  0.97  1.49  0.11  0.04  0.27 -0.1   0.26 -0.    0.33  0.04\n",
      "  0.01]\n",
      "Episode:1 Score:0.43820480313058224\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.99512504252297, 0.56) reward:0.43512504013878417\n",
      "[ 0.09  0.56  0.07  0.47  0.57  0.74  0.73  0.46  0.46  0.5   0.46  0.65\n",
      "  0.53  1.09  0.03  0.83 -0.03 -0.22  0.05  0.7  -0.74 -0.41 -0.22  0.17\n",
      "  0.52 -0.25  0.88  1.12 -0.13 -0.13  0.42  0.33  0.38  0.33  0.48 -0.07\n",
      " -0.11]\n",
      "Episode:1 Score:0.43512504013878417\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.7311536530979896, 0.61) reward:0.12115363879287488\n",
      "[ 0.64  0.61  0.56  0.55 -0.02 -0.19 -0.34  0.56  0.59  0.58  0.93  0.61\n",
      "  0.55  0.86 -0.02  0.7   0.02 -0.    0.02  0.59 -0.07  0.26  0.75  0.37\n",
      " -0.15  0.48  0.13  1.14  0.84  0.35 -0.34 -0.5  -0.4   0.72 -0.36 -0.3\n",
      " -0.22]\n",
      "Episode:1 Score:0.12115363879287488\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.122473423711747, -0.21) reward:0.3324734171552361\n",
      "[ 0.7  -0.21  0.71  0.45  0.39  0.06  0.21  0.48  0.48  0.5   0.56  0.62\n",
      "  0.5   1.08  0.12  0.74  0.31  0.05 -0.08  0.56 -0.59 -0.03  0.03  1.04\n",
      "  0.29  0.17  0.89  1.27  0.03 -0.03  0.47 -0.03  0.48  0.32  0.55  0.01\n",
      " -0.06]\n",
      "Episode:1 Score:0.3324734171552361\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0376931481901647, -0.38) reward:0.4176931434217931\n",
      "[ 0.78 -0.38  0.73  0.49  0.42  0.12  0.38  0.5   0.5   0.51  0.6   0.6\n",
      "  0.46  0.73  0.13  0.72  0.54  0.19 -0.14  0.51 -0.56  0.06  0.08  0.74\n",
      "  0.22  0.27  0.91  1.27  0.04  0.02  0.45 -0.05  0.42  0.26  0.48  0.08\n",
      " -0.08]\n",
      "Episode:1 Score:0.4176931434217931\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.852913387639546, 0.67) reward:0.1829133709502455\n",
      "[ 0.71  0.67  0.62  0.55 -0.91 -0.2  -0.68  0.59  0.61  0.63  1.12  0.69\n",
      "  0.58  0.96 -0.03  0.77 -0.01 -0.11  0.23  0.62  1.04  0.87  0.35  0.06\n",
      " -1.05  0.85 -0.26  0.33  0.45  0.12 -0.06 -0.32 -0.12  1.02 -0.08 -0.33\n",
      " -0.23]\n",
      "Episode:1 Score:0.1829133709502455\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0576694777013029, -0.26) reward:0.31766946816455977\n",
      "[ 0.77 -0.26  0.76  0.46  0.56 -0.01  0.48  0.46  0.48  0.47  0.47  0.6\n",
      "  0.48  0.68  0.22  0.7   0.23  0.09 -0.15  0.54 -0.46  0.44  0.42  0.69\n",
      " -0.28  0.54  0.94  1.66  0.44  0.32 -0.13 -0.44 -0.13 -0.42 -0.09  0.01\n",
      "  0.01]\n",
      "Episode:1 Score:0.31766946816455977\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0744354176429658, -0.29) reward:0.3644354092983155\n",
      "[ 0.79 -0.29  0.87  0.43  0.54  1.39  0.75  0.46  0.44  0.47  1.11  0.54\n",
      "  0.42  0.83  0.01  0.74  0.23 -0.04  0.04  0.52 -0.62 -0.22 -0.09  0.67\n",
      "  0.33 -0.09  1.08  1.11 -0.07 -0.08  0.4  -0.01  0.53  0.04  0.61 -0.07\n",
      " -0.2 ]\n",
      "Episode:1 Score:0.3644354092983155\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.9901307329521136, 0.75) reward:0.24013073295211362\n",
      "[ 0.16  0.75  0.12  0.32  0.63 -0.05  0.38  0.32  0.35  0.36  0.13  0.75\n",
      "  0.56  0.94  0.19  0.86 -0.07 -0.24  0.03  0.63 -0.37  0.08  0.1   0.09\n",
      " -0.24  0.06  1.03  1.64  0.22  0.22 -0.05 -0.11 -0.04 -0.6   0.02 -0.11\n",
      "  0.02]\n",
      "Episode:1 Score:0.24013073295211362\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "lit:(0.897741004138852, 0.78) reward:0.11774103274908154\n",
      "[ 0.65  0.78  0.69  0.41  0.48  0.02 -0.12  0.43  0.45  0.45  1.02  0.47\n",
      "  0.37  0.77  0.08  0.59  0.16  0.08 -0.13  0.42 -0.74 -0.09  0.36  0.69\n",
      "  0.23  0.15  0.73  1.38  0.45  0.15  0.13 -0.15  0.07  0.57  0.14 -0.08\n",
      " -0.08]\n",
      "Episode:1 Score:0.11774103274908154\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1381688298981236, -0.11) reward:0.24816882930207715\n",
      "[ 0.82 -0.11  0.81  0.41 -0.42 -0.16 -0.34  0.47  0.46  0.49  1.13  0.64\n",
      "  0.54  1.18  0.2   0.79  0.14 -0.11 -0.07  0.64  0.35  0.68  0.5   0.64\n",
      " -0.42  0.89  0.16  1.18  0.5   0.21 -0.07 -0.36 -0.34  0.8  -0.26  0.04\n",
      "  0.  ]\n",
      "Episode:1 Score:0.24816882930207715\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0334125277894992, -0.28) reward:0.3134125289815921\n",
      "[ 0.77 -0.28  0.77  0.4   0.3  -0.07 -0.02  0.43  0.43  0.45  1.04  0.5\n",
      "  0.43  0.75  0.16  0.64  0.22  0.11 -0.19  0.51 -0.57  0.11  0.36  0.4\n",
      "  0.21  0.42  0.64  1.33  0.37  0.09  0.06 -0.16 -0.22  0.55 -0.14  0.05\n",
      " -0.06]\n",
      "Episode:1 Score:0.3134125289815921\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.676456769550797, 0.51) reward:0.1664567790875402\n",
      "[ 0.65  0.51  0.69  0.37  0.65  1.09  0.65  0.39  0.4   0.4   1.05  0.49\n",
      "  0.36  0.63  0.07  0.7   0.17 -0.01 -0.02  0.45 -0.45  0.14  0.26  0.41\n",
      " -0.18  0.2   1.01  1.49  0.34  0.24 -0.06 -0.31 -0.01 -0.37  0.05 -0.14\n",
      " -0.14]\n",
      "Episode:1 Score:0.1664567790875402\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.142211654883424, -0.21) reward:0.3522116483269131\n",
      "[ 0.82 -0.21  0.84  0.43 -0.6  -0.24 -0.37  0.46  0.46  0.48  1.18  0.49\n",
      "  0.4   0.66  0.08  0.67  0.22 -0.01 -0.07  0.52  0.61  1.03  0.33  0.46\n",
      " -0.84  1.18  0.01  0.61  0.35  0.11  0.08 -0.26 -0.11  1.08 -0.04  0.09\n",
      " -0.09]\n",
      "Episode:1 Score:0.3522116483269131\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0743163684732353, -0.21) reward:0.2843163619167244\n",
      "[ 0.94 -0.21  0.87  0.69 -0.75 -0.22 -0.36  0.74  0.72  0.73  1.37  0.64\n",
      "  0.56  0.78  0.26  0.78  0.41  0.07  0.04  0.6   0.74  1.05  0.49  0.61\n",
      " -0.86  1.17 -0.06  0.81  0.5   0.19  0.01 -0.48 -0.22  1.05 -0.18  0.07\n",
      "  0.09]\n",
      "Episode:1 Score:0.2843163619167244\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1233058591275724, -0.15) reward:0.2733058650880369\n",
      "[ 0.73 -0.15  0.71  0.45  0.35  0.05  0.14  0.49  0.48  0.5   0.63  0.69\n",
      "  0.52  1.04  0.18  0.8   0.33  0.06 -0.06  0.55 -0.43  0.15  0.19  0.89\n",
      "  0.05  0.27  0.88  1.58  0.17  0.14  0.17 -0.15  0.11 -0.14  0.16 -0.04\n",
      " -0.05]\n",
      "Episode:1 Score:0.2733058650880369\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0884662559217874, -0.26) reward:0.34846624638504425\n",
      "[ 0.75 -0.26  0.74  0.45  0.53 -0.    0.45  0.47  0.49  0.49  0.42  0.65\n",
      "  0.49  0.95  0.23  0.79  0.32  0.06 -0.11  0.53 -0.44  0.33  0.23  0.78\n",
      " -0.2   0.4   1.08  1.77  0.25  0.27  0.04 -0.26  0.06 -0.54  0.09  0.01\n",
      "  0.01]\n",
      "Episode:1 Score:0.34846624638504425\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1071345591863701, -0.31) reward:0.4171345615705559\n",
      "[ 0.77 -0.31  0.8   0.43  0.42  1.02  0.4   0.48  0.48  0.5   1.02  0.65\n",
      "  0.5   1.18  0.27  0.88  0.37 -0.05 -0.03  0.57 -0.42  0.26  0.39  1.\n",
      " -0.08  0.38  0.95  1.69  0.43  0.34 -0.01 -0.41  0.01 -0.2   0.07  0.04\n",
      "  0.07]\n",
      "Episode:1 Score:0.4171345615705559\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.8564803188700207, 0.62) reward:0.23648031410164916\n",
      "[ 0.69  0.62  0.61  0.55 -0.88 -0.23 -0.62  0.59  0.6   0.62  1.08  0.64\n",
      "  0.57  0.92 -0.07  0.73 -0.05 -0.1   0.17  0.63  0.94  0.97  0.43  0.13\n",
      " -1.07  1.   -0.32  0.32  0.54  0.12 -0.07 -0.34 -0.1   1.17 -0.06 -0.32\n",
      " -0.25]\n",
      "Episode:1 Score:0.23648031410164916\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0416172269298309, -0.23) reward:0.271617231102156\n",
      "[ 0.85 -0.23  0.82  0.43 -0.34 -0.21 -0.29  0.47  0.47  0.49  1.12  0.55\n",
      "  0.47  0.83  0.17  0.7   0.21  0.02 -0.15  0.58  0.28  0.68  0.5   0.33\n",
      " -0.41  0.91  0.18  1.08  0.5   0.2  -0.09 -0.3  -0.38  0.91 -0.31  0.13\n",
      " -0.02]\n",
      "Episode:1 Score:0.271617231102156\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0876338205059619, -0.26) reward:0.34763381096921875\n",
      "[ 0.73 -0.26  0.74  0.43  0.52  0.01  0.42  0.45  0.47  0.47  0.41  0.67\n",
      "  0.51  1.05  0.24  0.82  0.23  0.   -0.1   0.56 -0.4   0.41  0.27  0.78\n",
      " -0.28  0.49  1.06  1.83  0.3   0.32 -0.04 -0.3  -0.05 -0.56 -0.01 -0.03\n",
      "  0.02]\n",
      "Episode:1 Score:0.34763381096921875\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0694411080721093, -0.18) reward:0.24944111522466667\n",
      "[ 0.83 -0.18  0.81  0.46 -0.34 -0.16 -0.22  0.5   0.51  0.53  1.14  0.6\n",
      "  0.49  1.    0.26  0.78  0.25 -0.01 -0.12  0.59  0.31  0.6   0.46  0.18\n",
      " -0.39  0.79  0.35  1.18  0.46  0.19 -0.04 -0.37 -0.31  0.74 -0.24  0.11\n",
      "  0.04]\n",
      "Episode:1 Score:0.24944111522466667\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0256837224039936, -0.32) reward:0.3456837152514362\n",
      "[ 0.75 -0.32  0.74  0.46  0.5   0.06  0.41  0.46  0.46  0.47  0.66  0.49\n",
      "  0.42  0.72  0.01  0.62  0.37  0.2  -0.18  0.51 -0.78 -0.09 -0.05  0.52\n",
      "  0.47  0.24  0.86  1.11 -0.06 -0.14  0.52  0.19  0.36  0.67  0.45  0.07\n",
      " -0.17]\n",
      "Episode:1 Score:0.3456837152514362\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1372176482366636, -0.16) reward:0.2972176446603849\n",
      "[ 0.68 -0.16  0.71  0.44  0.4   0.02  0.09  0.47  0.46  0.48  0.67  0.58\n",
      "  0.5   1.12  0.08  0.69  0.24  0.06 -0.15  0.57 -0.73 -0.04  0.13  1.09\n",
      "  0.39  0.23  0.79  1.28  0.14 -0.03  0.4  -0.01  0.36  0.55  0.44  0.01\n",
      " -0.08]\n",
      "Episode:1 Score:0.2972176446603849\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0738407776425051, -0.18) reward:0.25384078479506245\n",
      "[ 0.75 -0.18  0.76  0.39  0.23 -0.08 -0.08  0.43  0.43  0.45  1.05  0.52\n",
      "  0.44  0.95  0.16  0.66  0.17  0.05 -0.19  0.52 -0.48  0.1   0.35  0.32\n",
      "  0.17  0.38  0.58  1.29  0.37  0.09  0.02 -0.19 -0.26  0.54 -0.18  0.01\n",
      " -0.07]\n",
      "Episode:1 Score:0.25384078479506245\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0920334900763582, -0.23) reward:0.3220334942486833\n",
      "[ 0.84 -0.23  0.82  0.44 -0.43 -0.15 -0.28  0.49  0.48  0.51  1.14  0.61\n",
      "  0.52  1.07  0.23  0.78  0.19 -0.06 -0.12  0.63  0.37  0.75  0.39  0.44\n",
      " -0.49  0.95  0.21  1.08  0.4   0.15  0.02 -0.29 -0.25  0.82 -0.17  0.09\n",
      "  0.03]\n",
      "Episode:1 Score:0.3220334942486833\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.4189061592647669, 0.15) reward:0.2689061533043024\n",
      "[ 0.69  0.15  0.64  0.57  0.5   0.98  0.59  0.57  0.58  0.58  0.6   0.49\n",
      "  0.46  1.1  -0.13  0.59  0.1   0.09  0.22  0.55 -0.63 -0.26  0.06  0.98\n",
      "  0.44 -0.03  0.74  0.95  0.15 -0.02  0.36 -0.08  0.6   0.39  0.66 -0.25\n",
      " -0.27]\n",
      "Episode:1 Score:0.2689061533043024\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0753865993044256, -0.15) reward:0.22538660526489007\n",
      "[ 0.71 -0.15  0.75  0.44  0.41  0.08  0.29  0.48  0.47  0.5   1.09  0.52\n",
      "  0.44  1.14  0.07  0.67  0.2   0.04 -0.14  0.54 -0.68 -0.2  -0.09  0.14\n",
      "  0.42  0.06  0.89  1.22 -0.08 -0.18  0.39  0.17  0.2   0.47  0.29 -0.01\n",
      " -0.15]\n",
      "Episode:1 Score:0.22538660526489007\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.1508919448544856, -0.08) reward:0.23089194306634625\n",
      "[ 0.89 -0.08  0.84  0.6  -0.63 -0.09 -0.24  0.69  0.66  0.67  1.37  0.7\n",
      "  0.59  1.04  0.24  0.84  0.26 -0.06  0.15  0.61  0.67  0.8   0.43  0.88\n",
      " -0.65  0.94  0.03  0.78  0.44  0.17  0.07 -0.59 -0.13  0.74 -0.08 -0.09\n",
      "  0.01]\n",
      "Episode:1 Score:0.23089194306634625\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.92401906361921, 1.02) reward:0.09598091730730363\n",
      "[ 0.62  1.02  0.63  0.62  0.36  0.02 -0.12  0.64  0.65  0.63  1.24  0.51\n",
      "  0.45  0.83 -0.03  0.59  0.19  0.1  -0.04  0.44 -0.65 -0.14  0.55  0.88\n",
      "  0.2   0.1   0.46  1.21  0.66  0.19 -0.01 -0.4   0.06  0.69  0.11 -0.26\n",
      " -0.2 ]\n",
      "Episode:1 Score:0.09598091730730363\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0373366065291653, -0.37) reward:0.4073366112975369\n",
      "[ 0.78 -0.37  0.73  0.49  0.43  0.12  0.42  0.5   0.5   0.51  0.59  0.6\n",
      "  0.46  0.73  0.13  0.72  0.56  0.2  -0.13  0.51 -0.57  0.04  0.03  0.69\n",
      "  0.25  0.25  0.92  1.27 -0.01 -0.03  0.48 -0.01  0.42  0.26  0.48  0.08\n",
      " -0.09]\n",
      "Episode:1 Score:0.4073366112975369\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1029726850313388, -0.25) reward:0.35297268503133883\n",
      "[ 0.74 -0.25  0.73  0.44  0.48  0.    0.34  0.46  0.48  0.48  0.49  0.67\n",
      "  0.51  0.99  0.23  0.81  0.31  0.02 -0.1   0.54 -0.4   0.34  0.27  0.91\n",
      " -0.2   0.4   1.03  1.75  0.27  0.3   0.03 -0.3   0.05 -0.5   0.08 -0.\n",
      "  0.02]\n",
      "Episode:1 Score:0.35297268503133883\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.6166468301871133, 0.34) reward:0.2766468266108346\n",
      "[ 0.74  0.34  0.64  0.58 -0.94 -0.25 -0.64  0.63  0.64  0.65  1.09  0.68\n",
      "  0.58  0.89 -0.02  0.77 -0.02 -0.11  0.21  0.63  1.07  1.05  0.48  0.38\n",
      " -1.15  1.07 -0.32  0.34  0.57  0.19 -0.11 -0.42 -0.11  1.07 -0.07 -0.29\n",
      " -0.21]\n",
      "Episode:1 Score:0.2766468266108346\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "lit:(0.9927467854452244, 0.83) reward:0.16274680213452497\n",
      "[ 0.24  0.83  0.22  0.43  0.67  0.    0.47  0.42  0.42  0.45  0.4   0.7\n",
      "  0.51  0.38  0.06  0.77 -0.03 -0.17  0.1   0.58 -0.5  -0.2  -0.04  0.27\n",
      "  0.07 -0.21  1.04  1.33  0.03  0.07  0.2   0.03  0.31 -0.35  0.36 -0.1\n",
      " -0.1 ]\n",
      "Episode:1 Score:0.16274680213452497\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.7776455345807547, 0.68) reward:0.09764552742819732\n",
      "[ 0.65  0.68  0.55  0.5   0.46  0.06  0.19  0.49  0.54  0.52  0.52  0.63\n",
      "  0.51  0.98 -0.04  0.67  0.16  0.07  0.19  0.52 -0.35 -0.15  0.24  0.33\n",
      "  0.   -0.09  0.8   1.29  0.33  0.13  0.04 -0.32  0.32 -0.27  0.34 -0.35\n",
      " -0.29]\n",
      "Episode:1 Score:0.09764552742819732\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1286564074353324, -0.17) reward:0.29865640922347175\n",
      "[ 0.67 -0.17  0.71  0.44  0.41  0.03  0.12  0.47  0.46  0.48  0.67  0.58\n",
      "  0.5   1.11  0.07  0.7   0.25  0.06 -0.15  0.57 -0.73 -0.05  0.14  1.04\n",
      "  0.38  0.21  0.8   1.28  0.15 -0.04  0.38 -0.04  0.38  0.51  0.46  0.\n",
      " -0.09]\n",
      "Episode:1 Score:0.29865640922347175\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.8541023647163708, 0.7) reward:0.15410237663729975\n",
      "[ 0.67  0.7   0.7   0.39  0.49  0.01 -0.    0.41  0.43  0.43  1.03  0.44\n",
      "  0.35  0.7   0.06  0.57  0.18  0.13 -0.16  0.42 -0.73 -0.12  0.18  0.36\n",
      "  0.26  0.13  0.74  1.2   0.26 -0.02  0.22 -0.02  0.07  0.6   0.14 -0.07\n",
      " -0.12]\n",
      "Episode:1 Score:0.15410237663729975\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0852555634282161, -0.14) reward:0.22525556402426256\n",
      "[ 0.84 -0.14  0.82  0.44 -0.35 -0.13 -0.24  0.49  0.49  0.51  1.14  0.63\n",
      "  0.52  1.07  0.26  0.8   0.2  -0.06 -0.1   0.62  0.31  0.6   0.45  0.3\n",
      " -0.36  0.8   0.31  1.27  0.43  0.16 -0.01 -0.34 -0.31  0.74 -0.24  0.08\n",
      "  0.04]\n",
      "Episode:1 Score:0.22525556402426256\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0530323156396377, -0.27) reward:0.3230323263684738\n",
      "[ 0.77 -0.27  0.77  0.39  0.27 -0.08 -0.07  0.43  0.43  0.44  1.03  0.5\n",
      "  0.43  0.79  0.17  0.65  0.23  0.1  -0.2   0.51 -0.54  0.17  0.46  0.55\n",
      "  0.16  0.48  0.58  1.33  0.47  0.16 -0.01 -0.25 -0.27  0.59 -0.18  0.06\n",
      " -0.05]\n",
      "Episode:1 Score:0.3230323263684738\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.0478002106534163, -0.22) reward:0.26780020946132344\n",
      "[ 0.71 -0.22  0.71  0.44  0.4   0.03  0.24  0.45  0.45  0.47  0.72  0.55\n",
      "  0.47  0.96  0.03  0.67  0.22  0.11 -0.22  0.57 -0.67 -0.01  0.03  0.27\n",
      "  0.34  0.27  0.7   1.17  0.03 -0.12  0.32  0.12  0.12  0.53  0.2  -0.02\n",
      " -0.19]\n",
      "Episode:1 Score:0.26780020946132344\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0757431409654252, -0.38) reward:0.45574313619705364\n",
      "[ 0.88 -0.38  0.86  0.43 -0.56 -0.05 -0.24  0.5   0.48  0.52  1.16  0.71\n",
      "  0.55  1.03  0.37  0.91  0.3  -0.08 -0.01  0.64  0.58  0.79  0.25  0.39\n",
      " -0.6   0.92  0.29  0.95  0.23  0.04  0.21 -0.34 -0.07  0.73 -0.    0.12\n",
      "  0.13]\n",
      "Episode:1 Score:0.45574313619705364\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.616171239356383, 0.46) reward:0.1561712310117327\n",
      "[ 0.64  0.46  0.59  0.52  0.46  0.06  0.1   0.52  0.53  0.53  0.57  0.57\n",
      "  0.51  0.98 -0.07  0.6   0.14  0.1   0.1   0.55 -0.61 -0.35 -0.04  0.66\n",
      "  0.4  -0.16  0.77  0.98  0.05 -0.15  0.44  0.02  0.64  0.41  0.69 -0.23\n",
      " -0.22]\n",
      "Episode:1 Score:0.1561712310117327\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.2156955879408342, -0.11) reward:0.32569558734478776\n",
      "[ 0.71 -0.11  0.64  0.53  0.52 -0.06  0.33  0.54  0.57  0.54  0.31  0.66\n",
      "  0.54  0.94  0.05  0.76  0.17 -0.01  0.21  0.53 -0.28  0.32  0.51  1.11\n",
      " -0.29  0.42  0.92  1.47  0.59  0.35 -0.18 -0.7   0.16 -0.51  0.18 -0.26\n",
      " -0.15]\n",
      "Episode:1 Score:0.32569558734478776\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.5438762833757982, 0.39) reward:0.15387629768091293\n",
      "[ 0.52  0.39  0.58  0.42  0.58  0.99  0.64  0.42  0.42  0.43  0.87  0.45\n",
      "  0.38  0.66 -0.09  0.62  0.13  0.02 -0.08  0.52 -0.72 -0.18 -0.1   0.51\n",
      "  0.36  0.03  0.83  1.   -0.04 -0.1   0.47  0.15  0.48  0.52  0.56 -0.07\n",
      " -0.27]\n",
      "Episode:1 Score:0.15387629768091293\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0921522363219924, -0.22) reward:0.31215223512989954\n",
      "[ 0.68 -0.22  0.72  0.46  0.45  0.06  0.3   0.47  0.47  0.49  0.6   0.55\n",
      "  0.47  1.02  0.06  0.67  0.24  0.08 -0.15  0.56 -0.68 -0.11 -0.03  0.79\n",
      "  0.38  0.15  0.9   1.2  -0.01 -0.11  0.51  0.08  0.51  0.51  0.59  0.01\n",
      " -0.11]\n",
      "Episode:1 Score:0.31215223512989954\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.556480652086526, 0.28) reward:0.2764806508944331\n",
      "[ 0.73  0.28  0.65  0.57 -0.91 -0.28 -0.65  0.61  0.62  0.64  1.07  0.67\n",
      "  0.58  0.86 -0.04  0.76 -0.03 -0.12  0.19  0.63  1.02  1.08  0.51  0.47\n",
      " -1.15  1.12 -0.33  0.39  0.61  0.22 -0.16 -0.41 -0.19  1.07 -0.15 -0.28\n",
      " -0.21]\n",
      "Episode:1 Score:0.2764806508944331\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.2411415149294626, 0.01) reward:0.23114151515298\n",
      "[ 0.77  0.01  0.77  0.46  0.64 -0.01  0.64  0.47  0.48  0.47  0.43  0.59\n",
      "  0.42  0.55  0.16  0.72  0.29  0.06  0.06  0.46 -0.4   0.38  0.37  1.37\n",
      " -0.25  0.45  1.19  1.8   0.38  0.38  0.01 -0.44  0.19 -0.56  0.24  0.03\n",
      " -0.02]\n",
      "Episode:1 Score:0.23114151515298\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.912366179494038, 1.04) reward:0.12763378235898937\n",
      "[ 0.62  1.04  0.63  0.65  0.42 -0.   -0.13  0.67  0.67  0.64  1.23  0.48\n",
      "  0.41  0.62 -0.02  0.56  0.28  0.14 -0.04  0.39 -0.77 -0.16  0.64  1.15\n",
      "  0.28  0.09  0.52  1.21  0.73  0.19  0.04 -0.51  0.22  0.76  0.27 -0.2\n",
      " -0.17]\n",
      "Episode:1 Score:0.12763378235898937\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0765755763812505, -0.22) reward:0.2965755751891576\n",
      "[ 0.85 -0.22  0.83  0.45 -0.44 -0.17 -0.27  0.49  0.49  0.52  1.15  0.61\n",
      "  0.51  1.05  0.24  0.78  0.2  -0.04 -0.1   0.61  0.4   0.72  0.36  0.31\n",
      " -0.49  0.91  0.24  1.06  0.36  0.09  0.04 -0.27 -0.24  0.83 -0.17  0.09\n",
      "  0.03]\n",
      "Episode:1 Score:0.2965755751891576\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.7344827889130994, 0.51) reward:0.22448279844984254\n",
      "[ 0.62  0.51  0.62  0.42 -0.53 -0.24 -0.44  0.43  0.45  0.46  1.16  0.45\n",
      "  0.35  0.44  0.08  0.61  0.14 -0.   -0.1   0.47  0.58  0.94  0.32  0.23\n",
      " -0.88  1.03 -0.05  0.58  0.38  0.12  0.03 -0.21 -0.14  1.08 -0.08  0.05\n",
      " -0.08]\n",
      "Episode:1 Score:0.22448279844984254\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.9917956037837644, 0.78) reward:0.2117956323939939\n",
      "[ 0.14  0.78  0.12  0.39  0.19 -0.2  -0.22  0.38  0.39  0.41  0.68  0.63\n",
      "  0.52  0.44  0.06  0.72 -0.22 -0.2  -0.09  0.63 -0.23  0.2   0.56  0.13\n",
      " -0.14  0.35  0.36  1.31  0.65  0.32 -0.25 -0.23 -0.42  0.55 -0.35 -0.13\n",
      " -0.08]\n",
      "Episode:1 Score:0.2117956323939939\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.6277053772359207, 0.41) reward:0.21770538081219937\n",
      "[ 0.67  0.41  0.6   0.6   0.51  0.92  0.47  0.59  0.61  0.59  0.73  0.48\n",
      "  0.47  1.06 -0.15  0.6   0.1   0.11  0.18  0.55 -0.7  -0.24  0.18  0.76\n",
      "  0.46  0.03  0.66  1.03  0.29  0.03  0.25 -0.11  0.42  0.53  0.49 -0.28\n",
      " -0.29]\n",
      "Episode:1 Score:0.21770538081219937\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9952437887686048, 0.84) reward:0.15524381499464845\n",
      "[ 0.18  0.84  0.17  0.38  0.38 -0.14 -0.17  0.37  0.38  0.39  0.66  0.61\n",
      "  0.51  0.29  0.03  0.69 -0.2  -0.16 -0.06  0.61 -0.48  0.04  0.43  0.2\n",
      "  0.07  0.21  0.52  1.35  0.52  0.2  -0.12 -0.12 -0.29  0.5  -0.22 -0.14\n",
      " -0.1 ]\n",
      "Episode:1 Score:0.15524381499464845\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9941735579374142, 0.81) reward:0.18417355555322845\n",
      "[ 0.11  0.81  0.08  0.4   0.29 -0.18 -0.16  0.4   0.4   0.43  0.65  0.66\n",
      "  0.54  0.65  0.08  0.75 -0.19 -0.2  -0.1   0.66 -0.44 -0.    0.4   0.04\n",
      "  0.09  0.16  0.46  1.37  0.49  0.2  -0.14 -0.04 -0.35  0.52 -0.28 -0.11\n",
      " -0.05]\n",
      "Episode:1 Score:0.18417355555322845\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0468490289919563, -0.44) reward:0.4868490266077705\n",
      "[ 0.89 -0.44  0.86  0.42 -0.63 -0.16 -0.36  0.47  0.47  0.5   1.15  0.63\n",
      "  0.5   0.77  0.26  0.8   0.29 -0.03 -0.06  0.59  0.65  0.96  0.33  0.53\n",
      " -0.78  1.09  0.08  0.72  0.33  0.11  0.1  -0.3  -0.13  0.94 -0.06  0.17\n",
      "  0.07]\n",
      "Episode:1 Score:0.4868490266077705\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.7379309738979398, 0.44) reward:0.2979309762821256\n",
      "[ 0.62  0.44  0.6   0.5   0.59  0.03  0.26  0.51  0.53  0.56  0.57  0.67\n",
      "  0.48  0.79  0.06  0.77  0.12 -0.06  0.07  0.53 -0.38  0.    0.12  0.1\n",
      " -0.11  0.01  1.1   1.52  0.19  0.12  0.03 -0.16  0.15 -0.53  0.21 -0.21\n",
      " -0.14]\n",
      "Episode:1 Score:0.2979309762821256\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.050416263146527, -0.3) reward:0.350416275067456\n",
      "[ 0.77 -0.3   0.77  0.38  0.18 -0.1  -0.08  0.42  0.43  0.44  1.04  0.51\n",
      "  0.43  0.75  0.21  0.67  0.23  0.08 -0.2   0.51 -0.38  0.31  0.58  0.51\n",
      "  0.    0.6   0.51  1.37  0.59  0.26 -0.1  -0.39 -0.35  0.56 -0.28  0.06\n",
      " -0.01]\n",
      "Episode:1 Score:0.350416275067456\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0460165935761309, -0.29) reward:0.33601658523148065\n",
      "[ 0.78 -0.29  0.78  0.39  0.28 -0.07 -0.03  0.43  0.43  0.44  1.04  0.5\n",
      "  0.43  0.76  0.17  0.64  0.22  0.11 -0.2   0.51 -0.54  0.16  0.36  0.44\n",
      "  0.17  0.46  0.62  1.31  0.37  0.09  0.03 -0.16 -0.26  0.54 -0.18  0.05\n",
      " -0.05]\n",
      "Episode:1 Score:0.33601658523148065\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.8495839489003403, 0.74) reward:0.10958393936359712\n",
      "[ 0.7   0.74  0.59  0.58 -0.75 -0.29 -0.66  0.59  0.63  0.63  1.07  0.63\n",
      "  0.56  0.94 -0.08  0.71  0.   -0.02  0.1   0.62  0.78  0.79  0.6   0.03\n",
      " -0.84  0.87 -0.28  0.63  0.7   0.26 -0.28 -0.35 -0.38  1.13 -0.35 -0.3\n",
      " -0.26]\n",
      "Episode:1 Score:0.10958393936359712\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0569560914552078, -0.24) reward:0.2969560860907898\n",
      "[ 0.77 -0.24  0.77  0.39  0.29 -0.07 -0.06  0.43  0.43  0.44  1.03  0.5\n",
      "  0.43  0.78  0.16  0.64  0.2   0.1  -0.2   0.51 -0.55  0.15  0.38  0.49\n",
      "  0.18  0.45  0.6   1.33  0.4   0.13  0.02 -0.17 -0.27  0.55 -0.19  0.04\n",
      " -0.05]\n",
      "Episode:1 Score:0.2969560860907898\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.4778836632126251, 0.38) reward:0.09788366798099668\n",
      "[ 0.68  0.38  0.68  0.43 -0.32 -0.21 -0.35  0.44  0.46  0.46  1.15  0.48\n",
      "  0.39  0.63  0.04  0.65  0.15 -0.01 -0.08  0.51  0.3   0.64  0.53  0.16\n",
      " -0.43  0.83  0.1   1.01  0.55  0.23 -0.12 -0.3  -0.35  1.   -0.29  0.04\n",
      " -0.13]\n",
      "Episode:1 Score:0.09788366798099668\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0281807257273738, -0.23) reward:0.2581807298996989\n",
      "[ 0.72 -0.23  0.71  0.46  0.46  0.06  0.4   0.46  0.47  0.48  0.65  0.53\n",
      "  0.44  0.85  0.02  0.66  0.31  0.15 -0.21  0.54 -0.7  -0.01  0.07  0.27\n",
      "  0.34  0.27  0.77  1.22  0.07 -0.05  0.33  0.08  0.19  0.48  0.26  0.01\n",
      " -0.2 ]\n",
      "Episode:1 Score:0.2581807298996989\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.8368608339439778, 0.71) reward:0.12686085540164993\n",
      "[ 0.67  0.71  0.7   0.41  0.57  0.02  0.09  0.41  0.44  0.43  1.02  0.4\n",
      "  0.3   0.46  0.05  0.52  0.27  0.2  -0.15  0.36 -0.81 -0.1   0.3   0.55\n",
      "  0.25  0.15  0.79  1.23  0.38  0.1   0.2  -0.14  0.16  0.56  0.23 -0.02\n",
      " -0.12]\n",
      "Episode:1 Score:0.12686085540164993\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.1141499783257806, -0.24) reward:0.3541499729613626\n",
      "[ 0.85 -0.24  0.84  0.42 -0.45 -0.15 -0.29  0.48  0.46  0.49  1.14  0.62\n",
      "  0.53  1.13  0.22  0.79  0.17 -0.1  -0.07  0.64  0.4   0.78  0.39  0.61\n",
      " -0.51  0.98  0.18  1.02  0.39  0.12  0.05 -0.32 -0.2   0.83 -0.12  0.07\n",
      "  0.03]\n",
      "Episode:1 Score:0.3541499729613626\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0640902568402532, -0.43) reward:0.4940902639928106\n",
      "[ 1.14 -0.43  1.03  0.87 -0.73 -0.06 -0.23  0.87  0.86  0.85  1.4   0.59\n",
      "  0.56  0.44  0.36  0.81  0.6   0.36  0.01  0.7   0.62  1.25  0.66  0.73\n",
      " -0.88  1.46 -0.12  0.83  0.67  0.21  0.01 -0.5  -0.16  1.39 -0.11  0.32\n",
      "  0.27]\n",
      "Episode:1 Score:0.4940902639928106\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1533889481778663, -0.27) reward:0.42338895890670236\n",
      "[ 0.86 -0.27  0.85  0.39 -0.57 -0.06 -0.31  0.48  0.45  0.49  1.15  0.72\n",
      "  0.57  1.11  0.31  0.9   0.23 -0.16  0.04  0.64  0.6   0.83  0.32  0.73\n",
      " -0.63  0.97  0.2   0.95  0.31  0.12  0.16 -0.39 -0.09  0.71 -0.02  0.06\n",
      "  0.09]\n",
      "Episode:1 Score:0.42338895890670236\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9009513937083272, 0.67) reward:0.23095137701902668\n",
      "[ 0.68  0.67  0.59  0.53 -0.87 -0.24 -0.67  0.56  0.58  0.59  1.07  0.62\n",
      "  0.56  0.92 -0.09  0.7  -0.07 -0.1   0.15  0.63  0.91  0.97  0.39  0.09\n",
      " -1.06  1.01 -0.36  0.31  0.51  0.11 -0.07 -0.25 -0.15  1.24 -0.11 -0.32\n",
      " -0.25]\n",
      "Episode:1 Score:0.23095137701902668\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "lit:(0.5743162170111875, 0.53) reward:0.044316245621417005\n",
      "[ 0.56  0.53  0.61  0.38  0.43 -0.01  0.01  0.4   0.41  0.41  1.06  0.44\n",
      "  0.35  0.59  0.04  0.57  0.1   0.08 -0.11  0.43 -0.64 -0.06  0.35  0.28\n",
      "  0.22  0.19  0.68  1.31  0.4   0.09  0.06 -0.15 -0.09  0.55 -0.01 -0.07\n",
      " -0.16]\n",
      "Episode:1 Score:0.044316245621417005\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0963141104770237, -0.25) reward:0.3463141104770237\n",
      "[ 0.74 -0.25  0.74  0.44  0.49  0.    0.36  0.46  0.48  0.48  0.51  0.67\n",
      "  0.51  0.99  0.23  0.81  0.3   0.04 -0.1   0.55 -0.41  0.35  0.27  0.89\n",
      " -0.19  0.42  1.05  1.76  0.28  0.29  0.02 -0.31  0.04 -0.5   0.07 -0.\n",
      "  0.01]\n",
      "Episode:1 Score:0.3463141104770237\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.1229490145424769, -0.32) reward:0.44294900738991955\n",
      "[ 0.85 -0.32  0.84  0.41 -0.61 -0.1  -0.33  0.48  0.46  0.5   1.15  0.7\n",
      "  0.56  1.09  0.29  0.88  0.23 -0.14  0.01  0.64  0.63  0.87  0.34  0.68\n",
      " -0.68  1.01  0.16  0.92  0.33  0.12  0.12 -0.38 -0.11  0.76 -0.04  0.07\n",
      "  0.09]\n",
      "Episode:1 Score:0.44294900738991955\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0227111282498833, -0.4) reward:0.4227111342103478\n",
      "[ 0.79 -0.4   0.73  0.49  0.45  0.13  0.49  0.49  0.5   0.51  0.53  0.59\n",
      "  0.45  0.7   0.11  0.72  0.57  0.2  -0.12  0.5  -0.56  0.05  0.04  0.65\n",
      "  0.22  0.26  0.94  1.25  0.   -0.01  0.46 -0.04  0.42  0.22  0.48  0.07\n",
      " -0.1 ]\n",
      "Episode:1 Score:0.4227111342103478\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1366233111602992, -0.25) reward:0.3866233111602992\n",
      "[ 0.84 -0.25  0.83  0.41 -0.46 -0.15 -0.3   0.47  0.45  0.49  1.13  0.62\n",
      "  0.54  1.17  0.2   0.79  0.16 -0.11 -0.07  0.64  0.38  0.8   0.39  0.74\n",
      " -0.51  1.    0.15  1.    0.4   0.15  0.04 -0.31 -0.21  0.85 -0.13  0.07\n",
      "  0.03]\n",
      "Episode:1 Score:0.3866233111602992\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.3259214875269489, 0.21) reward:0.11592149408345981\n",
      "[ 0.57  0.21  0.55  0.45  0.57  0.11  0.58  0.44  0.46  0.46  0.48  0.59\n",
      "  0.41  0.57  0.08  0.71  0.33  0.11 -0.04  0.46 -0.45  0.16  0.26  0.58\n",
      " -0.1   0.22  1.    1.49  0.26  0.23  0.09 -0.32  0.24 -0.4   0.27 -0.07\n",
      " -0.16]\n",
      "Episode:1 Score:0.11592149408345981\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.195005872183601, 0.07) reward:0.12500587188557777\n",
      "[ 0.66  0.07  0.71  0.38  0.35 -0.03  0.06  0.41  0.4   0.41  1.08  0.46\n",
      "  0.37  0.69  0.05  0.6   0.09  0.05 -0.08  0.47 -0.54  0.03  0.37  0.39\n",
      "  0.2   0.3   0.68  1.33  0.4   0.16  0.03 -0.21 -0.14  0.49 -0.06 -0.06\n",
      " -0.17]\n",
      "Episode:1 Score:0.12500587188557777\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1021405525396097, -0.19) reward:0.2921405501554239\n",
      "[ 0.75 -0.19  0.71  0.46  0.4   0.07  0.27  0.49  0.49  0.51  0.58  0.69\n",
      "  0.52  1.    0.19  0.81  0.38  0.08 -0.08  0.55 -0.44  0.16  0.21  0.82\n",
      "  0.03  0.26  0.95  1.66  0.18  0.16  0.17 -0.19  0.18 -0.25  0.22 -0.02\n",
      " -0.06]\n",
      "Episode:1 Score:0.2921405501554239\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0927465733983572, -0.24) reward:0.33274656803393915\n",
      "[ 0.84 -0.24  0.83  0.44 -0.44 -0.16 -0.28  0.48  0.47  0.5   1.14  0.6\n",
      "  0.52  1.07  0.21  0.77  0.19 -0.07 -0.11  0.62  0.37  0.77  0.41  0.51\n",
      " -0.51  0.97  0.19  1.06  0.42  0.17  0.02 -0.31 -0.23  0.85 -0.15  0.1\n",
      "  0.02]\n",
      "Episode:1 Score:0.33274656803393915\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "lit:(0.0445898210839412, -0.14) reward:0.18458982167998766\n",
      "[ 0.91 -0.14  0.85  0.7  -0.62 -0.27 -0.33  0.73  0.73  0.73  1.36  0.59\n",
      "  0.55  0.79  0.19  0.71  0.34  0.1  -0.04  0.61  0.56  0.93  0.6   0.52\n",
      " -0.71  1.11 -0.05  0.94  0.62  0.26 -0.1  -0.48 -0.29  1.09 -0.25  0.08\n",
      "  0.04]\n",
      "Episode:1 Score:0.18458982167998766\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.5913199523682151, 0.51) reward:0.08131996190495827\n",
      "[ 0.64  0.51  0.64  0.43 -0.32 -0.22 -0.38  0.44  0.46  0.46  1.15  0.47\n",
      "  0.38  0.59  0.03  0.64  0.15  0.   -0.09  0.5   0.3   0.62  0.57  0.11\n",
      " -0.42  0.8   0.06  1.01  0.59  0.23 -0.17 -0.32 -0.39  1.03 -0.33  0.03\n",
      " -0.13]\n",
      "Episode:1 Score:0.08131996190495827\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0405469960986404, -0.45) reward:0.4905469841777115\n",
      "[ 0.88 -0.45  0.86  0.43 -0.53 -0.21 -0.32  0.47  0.46  0.49  1.14  0.56\n",
      "  0.48  0.81  0.21  0.74  0.25 -0.   -0.13  0.6   0.47  0.94  0.35  0.5\n",
      " -0.68  1.13  0.08  0.75  0.36  0.09  0.1  -0.24 -0.15  1.05 -0.07  0.18\n",
      "  0.04]\n",
      "Episode:1 Score:0.4905469841777115\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.6185494964341289, 0.34) reward:0.27854949285785024\n",
      "[ 0.62  0.34  0.6   0.49  0.58  0.03  0.28  0.5   0.52  0.55  0.51  0.68\n",
      "  0.5   0.93  0.07  0.78  0.13 -0.07  0.07  0.54 -0.38 -0.    0.08  0.07\n",
      " -0.1   0.    1.12  1.56  0.15  0.13  0.03 -0.14  0.15 -0.6   0.2  -0.2\n",
      " -0.13]\n",
      "Episode:1 Score:0.27854949285785024\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0208087649269634, -0.45) reward:0.4708087530060344\n",
      "[ 0.87 -0.45  0.84  0.43 -0.54 -0.23 -0.31  0.47  0.47  0.49  1.13  0.54\n",
      "  0.45  0.72  0.22  0.71  0.25  0.03 -0.12  0.57  0.51  0.97  0.31  0.36\n",
      " -0.76  1.15  0.08  0.67  0.33  0.08  0.11 -0.22 -0.14  1.06 -0.06  0.19\n",
      "  0.05]\n",
      "Episode:1 Score:0.4708087530060344\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0095124224627909, -0.28) reward:0.2895124236548838\n",
      "[ 0.73 -0.28  0.72  0.46  0.46  0.06  0.43  0.46  0.46  0.48  0.64  0.52\n",
      "  0.44  0.83  0.01  0.66  0.32  0.16 -0.21  0.54 -0.73 -0.05  0.01  0.24\n",
      "  0.39  0.25  0.77  1.14  0.   -0.12  0.39  0.14  0.21  0.56  0.3   0.01\n",
      " -0.2 ]\n",
      "Episode:1 Score:0.2895124236548838\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0367419665287049, -0.39) reward:0.4267419522235901\n",
      "[ 0.88 -0.39  0.85  0.43 -0.64 -0.22 -0.41  0.46  0.47  0.49  1.14  0.58\n",
      "  0.46  0.69  0.18  0.74  0.26 -0.02 -0.11  0.57  0.66  1.01  0.36  0.41\n",
      " -0.87  1.13  0.03  0.73  0.37  0.15  0.   -0.21 -0.24  1.   -0.18  0.17\n",
      "  0.02]\n",
      "Episode:1 Score:0.4267419522235901\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.1000000908772289, -0.31) reward:0.4100000932614147\n",
      "[ 0.79 -0.31  0.79  0.45  0.38  0.97  0.36  0.5   0.5   0.51  1.05  0.64\n",
      "  0.49  1.08  0.29  0.86  0.4  -0.02 -0.08  0.57 -0.45  0.16  0.28  0.74\n",
      "  0.04  0.29  0.96  1.66  0.3   0.21  0.1  -0.28  0.07 -0.11  0.13  0.06\n",
      "  0.08]\n",
      "Episode:1 Score:0.4100000932614147\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0634959197638889, -0.31) reward:0.3734959221480747\n",
      "[ 0.74 -0.31  0.72  0.49  0.52  0.34  0.61  0.5   0.51  0.52  0.47  0.67\n",
      "  0.48  0.92  0.15  0.81  0.47  0.12 -0.07  0.53 -0.47  0.15  0.26  0.64\n",
      " -0.03  0.22  1.11  1.65  0.23  0.23  0.11 -0.33  0.27 -0.5   0.31 -0.04\n",
      " -0.12]\n",
      "Episode:1 Score:0.3734959221480747\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1310346645130784, -0.13) reward:0.26103465974470685\n",
      "[ 0.83 -0.13  0.82  0.43 -0.44 -0.18 -0.35  0.48  0.47  0.5   1.14  0.63\n",
      "  0.54  1.16  0.19  0.78  0.15 -0.1  -0.08  0.63  0.37  0.71  0.5   0.6\n",
      " -0.44  0.91  0.15  1.13  0.5   0.21 -0.07 -0.36 -0.33  0.84 -0.26  0.05\n",
      " -0.  ]\n",
      "Episode:1 Score:0.26103465974470685\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.3946492093529632, 0.04) reward:0.3546492102470329\n",
      "[ 0.74  0.04  0.68  0.59 -0.85 -0.28 -0.53  0.64  0.63  0.65  1.05  0.66\n",
      "  0.58  0.88 -0.02  0.74 -0.07 -0.12  0.18  0.64  0.9   1.07  0.46  0.69\n",
      " -1.04  1.17 -0.3   0.3   0.54  0.17 -0.04 -0.41 -0.05  1.12 -0.   -0.25\n",
      " -0.18]\n",
      "Episode:1 Score:0.3546492102470329\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.1374554436520287, -0.16) reward:0.29745544007575\n",
      "[ 0.67 -0.16  0.71  0.43  0.4   0.02  0.07  0.47  0.45  0.48  0.69  0.57\n",
      "  0.5   1.13  0.07  0.69  0.23  0.06 -0.15  0.57 -0.74 -0.04  0.14  1.1\n",
      "  0.4   0.22  0.77  1.28  0.15 -0.04  0.37 -0.02  0.34  0.54  0.42 -0.\n",
      " -0.09]\n",
      "Episode:1 Score:0.29745544007575\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.1177169095562553, -0.23) reward:0.34771691372858043\n",
      "[ 0.72 -0.23  0.71  0.46  0.45  0.07  0.45  0.48  0.49  0.5   0.41  0.69\n",
      "  0.5   1.03  0.19  0.82  0.36  0.06 -0.03  0.53 -0.39  0.28  0.29  0.96\n",
      " -0.15  0.36  0.98  1.63  0.29  0.28  0.08 -0.33  0.18 -0.41  0.21 -0.05\n",
      " -0.05]\n",
      "Episode:1 Score:0.34771691372858043\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.8523187476390854, 0.51) reward:0.3423187571758286\n",
      "[ 0.84  0.51  0.69  0.64  0.46  0.01  0.14  0.62  0.62  0.61  0.7   0.64\n",
      "  0.46  0.22  0.1   0.76  0.86  0.27  0.18  0.42 -0.4   0.29  0.76  1.34\n",
      " -0.15  0.42  0.94  1.67  0.77  0.38 -0.02 -0.83  0.27  0.01  0.31 -0.1\n",
      " -0.04]\n",
      "Episode:1 Score:0.3423187571758286\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.4932225277380022, 0.34) reward:0.1532225241617235\n",
      "[ 0.56  0.34  0.54  0.43  0.65  0.06  0.68  0.42  0.45  0.43  0.35  0.58\n",
      "  0.41  0.53  0.16  0.73  0.27  0.09 -0.08  0.48 -0.41  0.37  0.32  0.62\n",
      " -0.32  0.42  1.07  1.66  0.35  0.29 -0.04 -0.39  0.05 -0.55  0.09 -0.04\n",
      " -0.07]\n",
      "Episode:1 Score:0.1532225241617235\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.07550534555006, -0.29) reward:0.36550533720540973\n",
      "[ 0.76 -0.29  0.73  0.46  0.47  0.05  0.43  0.48  0.5   0.5   0.55  0.67\n",
      "  0.5   0.89  0.25  0.81  0.41  0.08 -0.14  0.55 -0.44  0.23  0.24  0.68\n",
      " -0.09  0.31  1.08  1.75  0.21  0.22  0.13 -0.3   0.17 -0.47  0.21  0.03\n",
      "  0.01]\n",
      "Episode:1 Score:0.36550533720540973\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.1231868099578419, -0.33) reward:0.4531868230708638\n",
      "[ 0.87 -0.33  0.85  0.4  -0.56 -0.06 -0.27  0.49  0.46  0.5   1.16  0.72\n",
      "  0.58  1.1   0.34  0.91  0.24 -0.13  0.02  0.66  0.57  0.8   0.27  0.65\n",
      " -0.57  0.95  0.23  0.94  0.25  0.05  0.21 -0.37 -0.05  0.73  0.03  0.08\n",
      "  0.11]\n",
      "Episode:1 Score:0.4531868230708638\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0726514976415844, -0.52) reward:0.5926514785680981\n",
      "[ 0.81 -0.52  0.81  0.49  0.47  1.43  0.72  0.53  0.52  0.54  1.04  0.63\n",
      "  0.46  1.    0.25  0.9   0.53  0.04 -0.07  0.55 -0.55  0.03  0.25  0.56\n",
      "  0.14  0.14  1.13  1.53  0.25  0.18  0.11 -0.32  0.16 -0.25  0.23  0.06\n",
      "  0.03]\n",
      "Episode:1 Score:0.5926514785680981\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.922354495711655, 0.78) reward:0.14235452432188445\n",
      "[ 0.55  0.78  0.54  0.41 -0.53 -0.22 -0.48  0.43  0.45  0.46  1.15  0.48\n",
      "  0.35  0.35  0.11  0.66  0.19 -0.01 -0.08  0.46  0.62  0.87  0.35  0.17\n",
      " -0.88  0.91 -0.06  0.61  0.41  0.17 -0.02 -0.24 -0.22  1.02 -0.16  0.04\n",
      " -0.03]\n",
      "Episode:1 Score:0.14235452432188445\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0582641177017633, -0.54) reward:0.5982641391594354\n",
      "[ 0.83 -0.54  0.86  0.46  0.57  1.4   0.85  0.5   0.5   0.51  1.03  0.61\n",
      "  0.45  0.99  0.28  0.9   0.47  0.01 -0.09  0.56 -0.52  0.24  0.32  0.65\n",
      " -0.09  0.31  1.19  1.75  0.34  0.35 -0.05 -0.38 -0.01 -0.52  0.04  0.1\n",
      "  0.08]\n",
      "Episode:1 Score:0.5982641391594354\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0505353123162575, -0.47) reward:0.5205353111241646\n",
      "[ 0.88 -0.47  0.86  0.42 -0.52 -0.18 -0.28  0.47  0.46  0.49  1.14  0.58\n",
      "  0.5   0.83  0.25  0.77  0.27 -0.01 -0.11  0.61  0.45  0.91  0.35  0.52\n",
      " -0.63  1.11  0.11  0.75  0.35  0.05  0.15 -0.3  -0.08  1.04  0.    0.19\n",
      "  0.07]\n",
      "Episode:1 Score:0.5205353111241646\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0623069426870639, -0.11) reward:0.17230694209101746\n",
      "[ 0.81 -0.11  0.8   0.48 -0.35 -0.14 -0.24  0.51  0.51  0.53  1.14  0.59\n",
      "  0.52  0.9   0.2   0.72  0.19  0.02 -0.18  0.63  0.29  0.65  0.55  0.31\n",
      " -0.4   0.86  0.13  1.13  0.55  0.23 -0.12 -0.37 -0.39  0.89 -0.33  0.09\n",
      "  0.  ]\n",
      "Episode:1 Score:0.17230694209101746\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0731273913964105, -0.23) reward:0.30312739556873564\n",
      "[ 0.85 -0.23  0.83  0.45 -0.44 -0.17 -0.27  0.49  0.49  0.52  1.15  0.61\n",
      "  0.51  1.05  0.24  0.78  0.2  -0.04 -0.11  0.62  0.39  0.71  0.36  0.3\n",
      " -0.48  0.9   0.24  1.07  0.35  0.09  0.04 -0.27 -0.24  0.83 -0.17  0.1\n",
      "  0.03]\n",
      "Episode:1 Score:0.30312739556873564\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0269917486505488, -0.12) reward:0.14699174596833978\n",
      "[ 0.78 -0.12  0.68  0.74  0.48 -0.09  0.46  0.73  0.73  0.71  0.57  0.6\n",
      "  0.51  0.54  0.13  0.63  0.5   0.21 -0.04  0.48 -0.42  0.3   0.52  1.1\n",
      " -0.14  0.41  0.89  1.64  0.51  0.32  0.   -0.58  0.24 -0.32  0.25 -0.05\n",
      " -0.06]\n",
      "Episode:1 Score:0.14699174596833978\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.9891795512906538, 0.77) reward:0.21917957036414015\n",
      "[ 0.21  0.77  0.18  0.41  0.7   0.01  0.51  0.4   0.42  0.44  0.29  0.73\n",
      "  0.53  0.62  0.11  0.81 -0.02 -0.21  0.08  0.6  -0.43 -0.08  0.09  0.23\n",
      " -0.1  -0.11  1.08  1.5   0.18  0.21  0.05 -0.14  0.22 -0.58  0.28 -0.1\n",
      " -0.07]\n",
      "Episode:1 Score:0.21917957036414015\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.6410228292686473, 0.44) reward:0.20102283165283308\n",
      "[ 0.67  0.44  0.66  0.44 -0.57 -0.29 -0.51  0.44  0.46  0.47  1.14  0.44\n",
      "  0.34  0.44  0.03  0.6   0.17  0.01 -0.12  0.47  0.6   1.01  0.37  0.25\n",
      " -0.93  1.09 -0.13  0.6   0.44  0.16 -0.07 -0.16 -0.27  1.14 -0.22  0.06\n",
      " -0.1 ]\n",
      "Episode:1 Score:0.20102283165283308\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9134364103252286, 1.05) reward:0.13656354199105558\n",
      "[ 0.62  1.05  0.63  0.65  0.42 -0.   -0.13  0.67  0.67  0.64  1.23  0.48\n",
      "  0.41  0.62 -0.02  0.56  0.28  0.14 -0.04  0.39 -0.77 -0.17  0.64  1.15\n",
      "  0.28  0.09  0.52  1.22  0.74  0.19  0.04 -0.52  0.22  0.76  0.28 -0.2\n",
      " -0.17]\n",
      "Episode:1 Score:0.13656354199105558\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 17ms/step\n",
      "lit:(0.0658741768416346, -0.39) reward:0.45587416253651986\n",
      "[ 0.88 -0.39  0.85  0.42 -0.64 -0.17 -0.39  0.47  0.46  0.49  1.16  0.62\n",
      "  0.5   0.76  0.23  0.78  0.25 -0.05 -0.06  0.59  0.67  0.97  0.32  0.54\n",
      " -0.81  1.09  0.06  0.74  0.33  0.11  0.07 -0.26 -0.18  0.93 -0.11  0.14\n",
      "  0.05]\n",
      "Episode:1 Score:0.45587416253651986\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 18ms/step\n",
      "lit:(0.9931036300303198, 0.8) reward:0.1931036181093908\n",
      "[ 0.19  0.8   0.15  0.45  0.64 -0.01  0.46  0.44  0.45  0.48  0.4   0.73\n",
      "  0.54  0.64  0.1   0.8  -0.03 -0.19  0.08  0.61 -0.52 -0.26 -0.04  0.16\n",
      "  0.15 -0.26  1.02  1.42  0.03  0.04  0.18  0.07  0.27 -0.35  0.33 -0.1\n",
      " -0.08]\n",
      "Episode:1 Score:0.1931036181093908\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.9901307329521136, 0.79) reward:0.2001307114944415\n",
      "[ 0.13  0.79  0.1   0.39  0.19 -0.2  -0.2   0.37  0.39  0.4   0.68  0.62\n",
      "  0.52  0.46  0.06  0.72 -0.23 -0.2  -0.11  0.64 -0.25  0.2   0.58  0.13\n",
      " -0.12  0.36  0.34  1.35  0.67  0.34 -0.27 -0.22 -0.45  0.58 -0.38 -0.12\n",
      " -0.07]\n",
      "Episode:1 Score:0.2001307114944415\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.4768134323814348, 0.31) reward:0.16681342999724902\n",
      "[ 0.66  0.31  0.6   0.58  0.5   0.01  0.25  0.58  0.6   0.6   0.46  0.63\n",
      "  0.51  0.96 -0.06  0.66  0.12  0.07  0.21  0.52 -0.46 -0.25  0.11  0.81\n",
      "  0.19 -0.15  0.89  1.09  0.18  0.02  0.27 -0.26  0.64 -0.11  0.67 -0.31\n",
      " -0.28]\n",
      "Episode:1 Score:0.16681342999724902\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.8495839489003403, 0.73) reward:0.11958392982685395\n",
      "[ 0.65  0.73  0.69  0.41  0.51  0.03 -0.01  0.42  0.44  0.44  1.03  0.44\n",
      "  0.34  0.65  0.05  0.57  0.21  0.14 -0.16  0.41 -0.76 -0.12  0.29  0.43\n",
      "  0.25  0.13  0.72  1.19  0.37  0.05  0.17 -0.14  0.1   0.6   0.17 -0.07\n",
      " -0.14]\n",
      "Episode:1 Score:0.11958392982685395\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 15ms/step\n",
      "lit:(0.138525674483219, -0.12) reward:0.25852567180101\n",
      "[ 0.82 -0.12  0.81  0.42 -0.43 -0.18 -0.36  0.47  0.47  0.49  1.13  0.62\n",
      "  0.54  1.17  0.17  0.77  0.13 -0.11 -0.09  0.63  0.36  0.7   0.48  0.62\n",
      " -0.44  0.91  0.13  1.16  0.49  0.21 -0.09 -0.29 -0.38  0.85 -0.3   0.05\n",
      "  0.  ]\n",
      "Episode:1 Score:0.25852567180101\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.274078451888232, 0.13) reward:0.14407845665660357\n",
      "[ 0.73  0.13  0.73  0.43 -0.37 -0.21 -0.35  0.45  0.46  0.47  1.16  0.5\n",
      "  0.4   0.69  0.04  0.67  0.16 -0.03 -0.06  0.53  0.34  0.66  0.54  0.22\n",
      " -0.42  0.86  0.1   1.05  0.53  0.21 -0.13 -0.29 -0.38  1.   -0.31  0.04\n",
      " -0.13]\n",
      "Episode:1 Score:0.14407845665660357\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.0945304933997384, -0.15) reward:0.24453049936020288\n",
      "[ 0.7  -0.15  0.75  0.43  0.37  0.05  0.19  0.47  0.46  0.49  1.09  0.55\n",
      "  0.47  1.18  0.1   0.69  0.17  0.   -0.14  0.55 -0.63 -0.15 -0.02  0.27\n",
      "  0.35  0.09  0.84  1.24  0.   -0.14  0.33  0.06  0.19  0.4   0.28 -0.02\n",
      " -0.13]\n",
      "Episode:1 Score:0.24453049936020288\n",
      "init reached\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 16ms/step\n",
      "lit:(0.985850415475544, 0.71) reward:0.2758504369332161\n",
      "[ 0.09  0.71  0.02  0.48 -0.51 -0.39 -0.59  0.46  0.47  0.5   0.8   0.66\n",
      "  0.53  0.37  0.04  0.73 -0.18 -0.29 -0.1   0.67  0.49  0.72  0.44 -0.02\n",
      " -0.74  0.75 -0.11  0.79  0.52  0.21 -0.19 -0.02 -0.37  1.06 -0.3   0.02\n",
      " -0.02]\n",
      "Episode:1 Score:0.2758504369332161\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:28:32.762558Z",
     "start_time": "2024-09-25T18:28:32.758630Z"
    }
   },
   "cell_type": "code",
   "source": "lit101_list",
   "id": "e1200dca60a4e893",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.33],\n",
       " [-0.51],\n",
       " [-0.25],\n",
       " [-0.4],\n",
       " [-0.3],\n",
       " [-0.31],\n",
       " [-0.26],\n",
       " [-0.36],\n",
       " [-0.32],\n",
       " [-0.18],\n",
       " [-0.38],\n",
       " [-0.27],\n",
       " [-0.42],\n",
       " [-0.23],\n",
       " [-0.39],\n",
       " [-0.37],\n",
       " [-0.3],\n",
       " [-0.2],\n",
       " [-0.2],\n",
       " [-0.22],\n",
       " [-0.45],\n",
       " [-0.54],\n",
       " [-0.33],\n",
       " [-0.23],\n",
       " [-0.23],\n",
       " [0.09],\n",
       " [-0.25],\n",
       " [-0.48],\n",
       " [-0.18],\n",
       " [-0.37],\n",
       " [-0.43],\n",
       " [-0.33],\n",
       " [-0.42],\n",
       " [-0.12],\n",
       " [-0.21],\n",
       " [-0.4],\n",
       " [-0.47],\n",
       " [-0.39],\n",
       " [-0.26],\n",
       " [-0.2],\n",
       " [-0.2],\n",
       " [-0.23],\n",
       " [-0.28],\n",
       " [-0.13],\n",
       " [-0.43],\n",
       " [-0.36],\n",
       " [-0.33],\n",
       " [-0.22],\n",
       " [-0.39],\n",
       " [-0.42],\n",
       " [-0.4],\n",
       " [-0.21],\n",
       " [-0.09],\n",
       " [-0.41],\n",
       " [-0.42],\n",
       " [-0.4],\n",
       " [-0.25],\n",
       " [-0.27],\n",
       " [-0.16],\n",
       " [-0.32],\n",
       " [-0.23],\n",
       " [-0.26],\n",
       " [-0.4],\n",
       " [-0.39],\n",
       " [-0.13],\n",
       " [-0.34],\n",
       " [-0.44],\n",
       " [-0.41],\n",
       " [-0.31],\n",
       " [-0.44],\n",
       " [-0.41],\n",
       " [-0.26],\n",
       " [-0.2],\n",
       " [-0.14],\n",
       " [-0.41],\n",
       " [-0.22],\n",
       " [-0.08],\n",
       " [-0.4],\n",
       " [-0.13],\n",
       " [-0.32],\n",
       " [-0.35],\n",
       " [-0.2],\n",
       " [-0.23],\n",
       " [-0.15],\n",
       " [-0.25],\n",
       " [-0.48],\n",
       " [-0.49],\n",
       " [-0.23],\n",
       " [-0.44],\n",
       " [-0.44],\n",
       " [-0.12],\n",
       " [-0.33],\n",
       " [-0.42],\n",
       " [-0.18],\n",
       " [-0.32],\n",
       " [-0.36],\n",
       " [-0.24],\n",
       " [-0.12],\n",
       " [-0.25],\n",
       " [-0.31],\n",
       " [-0.17],\n",
       " [-0.35],\n",
       " [-0.28],\n",
       " [-0.27],\n",
       " [-0.35],\n",
       " [-0.42],\n",
       " [-0.24],\n",
       " [-0.27],\n",
       " [-0.35],\n",
       " [-0.25],\n",
       " [-0.35],\n",
       " [-0.3],\n",
       " [-0.25],\n",
       " [-0.32],\n",
       " [-0.27],\n",
       " [-0.23],\n",
       " [-0.23],\n",
       " [0.1],\n",
       " [-0.41],\n",
       " [-0.35],\n",
       " [-0.28],\n",
       " [-0.16],\n",
       " [-0.1],\n",
       " [-0.3],\n",
       " [-0.15],\n",
       " [-0.23],\n",
       " [-0.32],\n",
       " [-0.27],\n",
       " [-0.46],\n",
       " [-0.16],\n",
       " [-0.33],\n",
       " [-0.15],\n",
       " [-0.31],\n",
       " [-0.28],\n",
       " [-0.23],\n",
       " [0.13],\n",
       " [-0.3],\n",
       " [-0.22],\n",
       " [-0.21],\n",
       " [-0.22],\n",
       " [-0.16],\n",
       " [-0.18],\n",
       " [-0.49],\n",
       " [-0.3],\n",
       " [-0.35],\n",
       " [-0.34],\n",
       " [-0.11],\n",
       " [-0.3],\n",
       " [-0.1],\n",
       " [-0.26],\n",
       " [-0.13],\n",
       " [-0.35],\n",
       " [-0.49],\n",
       " [-0.42],\n",
       " [-0.23],\n",
       " [-0.04],\n",
       " [-0.35],\n",
       " [-0.44],\n",
       " [-0.42],\n",
       " [-0.39],\n",
       " [-0.12],\n",
       " [-0.13],\n",
       " [-0.29],\n",
       " [-0.33],\n",
       " [-0.18],\n",
       " [-0.08],\n",
       " [-0.49],\n",
       " [-0.28],\n",
       " [-0.47],\n",
       " [-0.29],\n",
       " [-0.43],\n",
       " [-0.41],\n",
       " [-0.37],\n",
       " [-0.26],\n",
       " [-0.35],\n",
       " [-0.3],\n",
       " [-0.35],\n",
       " [-0.34],\n",
       " [-0.15],\n",
       " [-0.37],\n",
       " [-0.45],\n",
       " [-0.59],\n",
       " [-0.14],\n",
       " [-0.6],\n",
       " [-0.52],\n",
       " [-0.17],\n",
       " [-0.3],\n",
       " [-0.15],\n",
       " [-0.22],\n",
       " [-0.2],\n",
       " [0.14],\n",
       " [-0.46],\n",
       " [-0.19],\n",
       " [-0.2],\n",
       " [-0.17],\n",
       " [-0.12],\n",
       " [-0.26],\n",
       " [-0.14],\n",
       " [-0.24],\n",
       " [-0.28]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "self.lit101_value_record.",
   "id": "90acfe8b168d486a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.929998852Z",
     "start_time": "2024-09-25T18:07:18.878456Z"
    }
   },
   "cell_type": "code",
   "source": "values_dict, input_windows = run_random_trials(data_array, model_window, SwatEnv,200, 5)\n",
   "id": "3691c85e7dc0578b",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[77], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m values_dict, input_windows \u001B[38;5;241m=\u001B[39m \u001B[43mrun_random_trials\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_array\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_window\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mSwatEnv\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[75], line 8\u001B[0m, in \u001B[0;36mrun_random_trials\u001B[0;34m(environment, data_array, window_size, episode_length, number_of_trials)\u001B[0m\n\u001B[1;32m      4\u001B[0m values_dict \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m      5\u001B[0m input_windows \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m----> 8\u001B[0m data_length \u001B[38;5;241m=\u001B[39m \u001B[43mdata_array\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      9\u001B[0m window_size \u001B[38;5;241m=\u001B[39m model_window \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     11\u001B[0m values_dict \u001B[38;5;241m=\u001B[39m {}\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'int' object has no attribute 'shape'"
     ]
    }
   ],
   "execution_count": 77
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.930192266Z",
     "start_time": "2024-09-25T16:39:47.688177Z"
    }
   },
   "cell_type": "code",
   "source": "values_dict",
   "id": "26d11bc7cbed2879",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0.09,\n",
       "  -0.29,\n",
       "  -0.54,\n",
       "  -0.71,\n",
       "  -0.82,\n",
       "  -0.89,\n",
       "  -0.93,\n",
       "  -0.95,\n",
       "  -0.94,\n",
       "  -0.91,\n",
       "  -0.89,\n",
       "  -0.87,\n",
       "  -0.85,\n",
       "  -0.83,\n",
       "  -0.81,\n",
       "  -0.79,\n",
       "  -0.77,\n",
       "  -0.75,\n",
       "  -0.73,\n",
       "  -0.7,\n",
       "  -0.68,\n",
       "  -0.65,\n",
       "  -0.62,\n",
       "  -0.59,\n",
       "  -0.56,\n",
       "  -0.53,\n",
       "  -0.49,\n",
       "  -0.45,\n",
       "  -0.4,\n",
       "  -0.35,\n",
       "  -0.29,\n",
       "  -0.22,\n",
       "  -0.14,\n",
       "  -0.04,\n",
       "  0.07,\n",
       "  0.2,\n",
       "  0.36,\n",
       "  0.55,\n",
       "  0.77,\n",
       "  1.02,\n",
       "  1.29,\n",
       "  1.56,\n",
       "  1.83,\n",
       "  2.08,\n",
       "  2.3,\n",
       "  2.46,\n",
       "  2.51,\n",
       "  2.49,\n",
       "  2.44,\n",
       "  2.39,\n",
       "  2.35,\n",
       "  2.33,\n",
       "  2.33,\n",
       "  2.34,\n",
       "  2.34,\n",
       "  2.33,\n",
       "  2.31,\n",
       "  2.28,\n",
       "  2.25,\n",
       "  2.22,\n",
       "  2.2,\n",
       "  2.18,\n",
       "  2.16,\n",
       "  2.15,\n",
       "  2.14,\n",
       "  2.14,\n",
       "  2.14,\n",
       "  2.14,\n",
       "  2.14,\n",
       "  2.14,\n",
       "  2.14,\n",
       "  2.15,\n",
       "  2.16,\n",
       "  2.17,\n",
       "  2.19,\n",
       "  2.21,\n",
       "  2.24,\n",
       "  2.27,\n",
       "  2.3,\n",
       "  2.33,\n",
       "  2.36,\n",
       "  2.39,\n",
       "  2.41,\n",
       "  2.43,\n",
       "  2.44,\n",
       "  2.44,\n",
       "  2.42,\n",
       "  2.39,\n",
       "  2.33,\n",
       "  2.25,\n",
       "  2.15,\n",
       "  2.09,\n",
       "  2.09,\n",
       "  2.12,\n",
       "  2.15,\n",
       "  2.18,\n",
       "  2.19,\n",
       "  2.18,\n",
       "  2.14,\n",
       "  2.11,\n",
       "  2.06,\n",
       "  2.05,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  1.95,\n",
       "  1.97,\n",
       "  1.93,\n",
       "  1.95,\n",
       "  1.92,\n",
       "  1.93,\n",
       "  1.9,\n",
       "  1.91,\n",
       "  1.89,\n",
       "  1.9,\n",
       "  1.89,\n",
       "  1.89,\n",
       "  1.89,\n",
       "  1.88,\n",
       "  1.89,\n",
       "  1.87,\n",
       "  1.9,\n",
       "  1.87,\n",
       "  1.91,\n",
       "  1.88,\n",
       "  1.91,\n",
       "  1.89,\n",
       "  1.91,\n",
       "  1.89,\n",
       "  1.91,\n",
       "  1.89,\n",
       "  1.9,\n",
       "  1.88,\n",
       "  1.88,\n",
       "  1.88,\n",
       "  1.88,\n",
       "  1.89,\n",
       "  1.87,\n",
       "  1.9,\n",
       "  1.87,\n",
       "  1.9,\n",
       "  1.87,\n",
       "  1.91,\n",
       "  1.88,\n",
       "  1.91,\n",
       "  1.88,\n",
       "  1.9,\n",
       "  1.88,\n",
       "  1.9,\n",
       "  1.88,\n",
       "  1.89,\n",
       "  1.89,\n",
       "  1.88,\n",
       "  1.89,\n",
       "  1.87,\n",
       "  1.9,\n",
       "  1.87,\n",
       "  1.9,\n",
       "  1.87,\n",
       "  1.91,\n",
       "  1.88,\n",
       "  1.91,\n",
       "  1.89,\n",
       "  1.91,\n",
       "  1.88,\n",
       "  1.9,\n",
       "  1.88,\n",
       "  1.89,\n",
       "  1.88,\n",
       "  1.88,\n",
       "  1.89,\n",
       "  1.87,\n",
       "  1.9,\n",
       "  1.87,\n",
       "  1.91,\n",
       "  1.88,\n",
       "  1.91,\n",
       "  1.88,\n",
       "  1.91,\n",
       "  1.89,\n",
       "  1.91,\n",
       "  1.88,\n",
       "  1.9,\n",
       "  1.88,\n",
       "  1.89,\n",
       "  1.88,\n",
       "  1.88,\n",
       "  1.88,\n",
       "  1.87,\n",
       "  1.89,\n",
       "  1.87,\n",
       "  1.9,\n",
       "  1.87,\n",
       "  1.91,\n",
       "  1.88,\n",
       "  1.91,\n",
       "  1.89,\n",
       "  1.91,\n",
       "  1.89,\n",
       "  1.91,\n",
       "  1.89],\n",
       " 1: [0.41,\n",
       "  0.31,\n",
       "  0.17,\n",
       "  0.1,\n",
       "  0.04,\n",
       "  -0.01,\n",
       "  -0.06,\n",
       "  -0.1,\n",
       "  -0.14,\n",
       "  -0.18,\n",
       "  -0.21,\n",
       "  -0.24,\n",
       "  -0.27,\n",
       "  -0.3,\n",
       "  -0.32,\n",
       "  -0.34,\n",
       "  -0.36,\n",
       "  -0.38,\n",
       "  -0.4,\n",
       "  -0.42,\n",
       "  -0.43,\n",
       "  -0.45,\n",
       "  -0.46,\n",
       "  -0.47,\n",
       "  -0.49,\n",
       "  -0.5,\n",
       "  -0.51,\n",
       "  -0.53,\n",
       "  -0.54,\n",
       "  -0.55,\n",
       "  -0.56,\n",
       "  -0.57,\n",
       "  -0.58,\n",
       "  -0.59,\n",
       "  -0.6,\n",
       "  -0.61,\n",
       "  -0.63,\n",
       "  -0.64,\n",
       "  -0.65,\n",
       "  -0.66,\n",
       "  -0.68,\n",
       "  -0.69,\n",
       "  -0.7,\n",
       "  -0.72,\n",
       "  -0.73,\n",
       "  -0.74,\n",
       "  -0.75,\n",
       "  -0.76,\n",
       "  -0.78,\n",
       "  -0.79,\n",
       "  -0.8,\n",
       "  -0.81,\n",
       "  -0.82,\n",
       "  -0.83,\n",
       "  -0.85,\n",
       "  -0.86,\n",
       "  -0.87,\n",
       "  -0.88,\n",
       "  -0.89,\n",
       "  -0.9,\n",
       "  -0.91,\n",
       "  -0.92,\n",
       "  -0.93,\n",
       "  -0.94,\n",
       "  -0.95,\n",
       "  -0.96,\n",
       "  -0.97,\n",
       "  -0.98,\n",
       "  -0.99,\n",
       "  -1.0,\n",
       "  -1.01,\n",
       "  -1.02,\n",
       "  -1.02,\n",
       "  -1.03,\n",
       "  -1.03,\n",
       "  -1.03,\n",
       "  -1.03,\n",
       "  -1.04,\n",
       "  -1.04,\n",
       "  -1.04,\n",
       "  -1.04,\n",
       "  -1.04,\n",
       "  -1.03,\n",
       "  -1.01,\n",
       "  -0.99,\n",
       "  -0.96,\n",
       "  -0.93,\n",
       "  -0.9,\n",
       "  -0.87,\n",
       "  -0.84,\n",
       "  -0.81,\n",
       "  -0.78,\n",
       "  -0.75,\n",
       "  -0.72,\n",
       "  -0.69,\n",
       "  -0.65,\n",
       "  -0.61,\n",
       "  -0.57,\n",
       "  -0.53,\n",
       "  -0.49,\n",
       "  -0.45,\n",
       "  -0.41,\n",
       "  -0.36,\n",
       "  -0.31,\n",
       "  -0.25,\n",
       "  -0.19,\n",
       "  -0.11,\n",
       "  -0.02,\n",
       "  0.09,\n",
       "  0.22,\n",
       "  0.37,\n",
       "  0.55,\n",
       "  0.76,\n",
       "  1.0,\n",
       "  1.26,\n",
       "  1.53,\n",
       "  1.79,\n",
       "  2.04,\n",
       "  2.27,\n",
       "  2.44,\n",
       "  2.5,\n",
       "  2.49,\n",
       "  2.45,\n",
       "  2.4,\n",
       "  2.36,\n",
       "  2.33,\n",
       "  2.33,\n",
       "  2.34,\n",
       "  2.34,\n",
       "  2.33,\n",
       "  2.32,\n",
       "  2.29,\n",
       "  2.26,\n",
       "  2.23,\n",
       "  2.2,\n",
       "  2.17,\n",
       "  2.15,\n",
       "  2.14,\n",
       "  2.13,\n",
       "  2.12,\n",
       "  2.12,\n",
       "  2.12,\n",
       "  2.12,\n",
       "  2.12,\n",
       "  2.12,\n",
       "  2.13,\n",
       "  2.14,\n",
       "  2.15,\n",
       "  2.17,\n",
       "  2.19,\n",
       "  2.22,\n",
       "  2.25,\n",
       "  2.28,\n",
       "  2.31,\n",
       "  2.34,\n",
       "  2.37,\n",
       "  2.4,\n",
       "  2.42,\n",
       "  2.43,\n",
       "  2.43,\n",
       "  2.42,\n",
       "  2.4,\n",
       "  2.36,\n",
       "  2.3,\n",
       "  2.21,\n",
       "  2.13,\n",
       "  2.09,\n",
       "  2.11,\n",
       "  2.14,\n",
       "  2.17,\n",
       "  2.19,\n",
       "  2.19,\n",
       "  2.17,\n",
       "  2.13,\n",
       "  2.1,\n",
       "  2.05,\n",
       "  2.03,\n",
       "  1.99,\n",
       "  1.99,\n",
       "  1.95,\n",
       "  1.96,\n",
       "  1.92,\n",
       "  1.94,\n",
       "  1.9,\n",
       "  1.93,\n",
       "  1.9,\n",
       "  1.92,\n",
       "  1.89,\n",
       "  1.91,\n",
       "  1.89,\n",
       "  1.9,\n",
       "  1.89,\n",
       "  1.89,\n",
       "  1.89,\n",
       "  1.88,\n",
       "  1.89,\n",
       "  1.87,\n",
       "  1.9,\n",
       "  1.87,\n",
       "  1.91],\n",
       " 2: [0.09,\n",
       "  -0.32,\n",
       "  -0.6,\n",
       "  -0.75,\n",
       "  -0.83,\n",
       "  -0.87,\n",
       "  -0.9,\n",
       "  -0.92,\n",
       "  -0.93,\n",
       "  -0.94,\n",
       "  -0.95,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.97,\n",
       "  -0.97,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.98,\n",
       "  -0.97,\n",
       "  -0.97,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.95,\n",
       "  -0.95,\n",
       "  -0.94,\n",
       "  -0.93,\n",
       "  -0.92,\n",
       "  -0.92,\n",
       "  -0.91,\n",
       "  -0.9,\n",
       "  -0.89,\n",
       "  -0.88,\n",
       "  -0.87,\n",
       "  -0.86,\n",
       "  -0.85,\n",
       "  -0.84,\n",
       "  -0.83,\n",
       "  -0.82,\n",
       "  -0.8,\n",
       "  -0.79,\n",
       "  -0.77,\n",
       "  -0.76,\n",
       "  -0.74,\n",
       "  -0.73,\n",
       "  -0.71,\n",
       "  -0.7,\n",
       "  -0.69,\n",
       "  -0.68,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74],\n",
       " 3: [0.98,\n",
       "  0.91,\n",
       "  0.57,\n",
       "  0.28,\n",
       "  0.04,\n",
       "  -0.16,\n",
       "  -0.33,\n",
       "  -0.47,\n",
       "  -0.58,\n",
       "  -0.67,\n",
       "  -0.74,\n",
       "  -0.79,\n",
       "  -0.83,\n",
       "  -0.86,\n",
       "  -0.89,\n",
       "  -0.91,\n",
       "  -0.93,\n",
       "  -0.94,\n",
       "  -0.95,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.95,\n",
       "  -0.95,\n",
       "  -0.94,\n",
       "  -0.93,\n",
       "  -0.92,\n",
       "  -0.92,\n",
       "  -0.91,\n",
       "  -0.9,\n",
       "  -0.89,\n",
       "  -0.88,\n",
       "  -0.87,\n",
       "  -0.86,\n",
       "  -0.85,\n",
       "  -0.83,\n",
       "  -0.82,\n",
       "  -0.8,\n",
       "  -0.78,\n",
       "  -0.77,\n",
       "  -0.75,\n",
       "  -0.73,\n",
       "  -0.72,\n",
       "  -0.7,\n",
       "  -0.69,\n",
       "  -0.68,\n",
       "  -0.67,\n",
       "  -0.66,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.64,\n",
       "  -0.64,\n",
       "  -0.64,\n",
       "  -0.64,\n",
       "  -0.64,\n",
       "  -0.64,\n",
       "  -0.64,\n",
       "  -0.64,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74],\n",
       " 4: [0.06,\n",
       "  -0.15,\n",
       "  -0.26,\n",
       "  -0.32,\n",
       "  -0.4,\n",
       "  -0.49,\n",
       "  -0.57,\n",
       "  -0.64,\n",
       "  -0.71,\n",
       "  -0.77,\n",
       "  -0.82,\n",
       "  -0.85,\n",
       "  -0.88,\n",
       "  -0.9,\n",
       "  -0.91,\n",
       "  -0.92,\n",
       "  -0.93,\n",
       "  -0.94,\n",
       "  -0.95,\n",
       "  -0.95,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.96,\n",
       "  -0.95,\n",
       "  -0.95,\n",
       "  -0.95,\n",
       "  -0.94,\n",
       "  -0.94,\n",
       "  -0.93,\n",
       "  -0.93,\n",
       "  -0.92,\n",
       "  -0.91,\n",
       "  -0.91,\n",
       "  -0.9,\n",
       "  -0.89,\n",
       "  -0.88,\n",
       "  -0.87,\n",
       "  -0.86,\n",
       "  -0.85,\n",
       "  -0.84,\n",
       "  -0.83,\n",
       "  -0.82,\n",
       "  -0.81,\n",
       "  -0.8,\n",
       "  -0.78,\n",
       "  -0.76,\n",
       "  -0.75,\n",
       "  -0.73,\n",
       "  -0.72,\n",
       "  -0.71,\n",
       "  -0.69,\n",
       "  -0.68,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.65,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.66,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.67,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.68,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.69,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.7,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.71,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.72,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.73,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74,\n",
       "  -0.74]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.930806497Z",
     "start_time": "2024-09-25T16:39:49.667708Z"
    }
   },
   "cell_type": "code",
   "source": "input_windows.keys()",
   "id": "1e6ebaa5412d7b0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 68
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.930958078Z",
     "start_time": "2024-09-25T16:39:51.358680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trial_window = input_windows[0]\n",
    "\n",
    "trial_window[0,-1,36]\n"
   ],
   "id": "57d780e32f43992e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931081775Z",
     "start_time": "2024-09-25T16:39:52.402748Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# final value for lit\n",
    "for key,window in input_windows.items():\n",
    "    print(window[0,-1,:][component_pos['LIT101']])"
   ],
   "id": "d95df635178f7808",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0872769759208664\n",
      "0.4053509118166749\n",
      "0.0870394834295975\n",
      "0.978121307165942\n",
      "0.0617123026866035\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931170018Z",
     "start_time": "2024-09-25T16:42:03.690232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for key, value in values_dict.items():\n",
    "\n",
    "    #for item in value:\n",
    "    plt.plot(value, label=f'Episode {key}')\n",
    "\n",
    "plt.xlabel('Time Steps')\n",
    "plt.ylabel('LIT101 Level')\n",
    "plt.title('LIT101 with MV101 On')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig('/home/loz/Documents/GitHub/MSc-Project/Write_Up/Charts/MV101_held_high.jpeg')\n",
    "#plt.savefig('/home/loz/Documents/GitHub/MSc-Project/Write_Up/Charts/LIT101_no_actions.jpeg')\n",
    "plt.show()\n",
    "\n",
    "\n"
   ],
   "id": "c015e565f7ae7fca",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931283496Z",
     "start_time": "2024-09-25T15:53:50.035999Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a4c40be9fa4bc99e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Create Deep Policy Table",
   "id": "71582d3749d8b6e1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Create Deep Learning Model#"
   ],
   "id": "8cbe185c6d90d1ec"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931397949Z",
     "start_time": "2024-09-25T15:53:50.086414Z"
    }
   },
   "cell_type": "code",
   "source": [],
   "id": "6c984dd207cab06e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931501989Z",
     "start_time": "2024-09-25T15:53:50.130598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "states = env.observation_space.shape\n",
    "actions = env.action_space.n"
   ],
   "id": "803ec7a6019f3243",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m states \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241m.\u001B[39mobservation_space\u001B[38;5;241m.\u001B[39mshape\n\u001B[1;32m      2\u001B[0m actions \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39maction_space\u001B[38;5;241m.\u001B[39mn\n",
      "\u001B[0;31mNameError\u001B[0m: name 'env' is not defined"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931609409Z",
     "start_time": "2024-09-25T12:22:52.679141Z"
    }
   },
   "id": "3603941aef4b2538",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "states"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931688372Z",
     "start_time": "2024-09-25T12:22:52.729520Z"
    }
   },
   "id": "69ba5c3d076535ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 37)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931797248Z",
     "start_time": "2024-09-25T12:22:52.785232Z"
    }
   },
   "cell_type": "code",
   "source": [
    "actions"
   ],
   "id": "a30d0d67fec2b5bf",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931892629Z",
     "start_time": "2024-09-25T12:22:52.840762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_model(states, actions):\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(24, activation='relu', input_shape=states))\n",
    "    #model.add(Dense(24, activation='relu', input_shape=(1,)))\n",
    "    model.add(Dense(24, activation='relu'))\n",
    "    model.add(Dense(actions, activation='linear'))\n",
    "    return model"
   ],
   "id": "ed2f0a9118190377",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.931966182Z",
     "start_time": "2024-09-25T12:22:52.889261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#del model"
   ],
   "id": "69758ce59d7ad830",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.932039351Z",
     "start_time": "2024-09-25T12:22:52.942523Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = build_model(states, actions)"
   ],
   "id": "6ba60cf6161d3e4c",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/loz/Documents/GitHub/MSc-Project/venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.932120769Z",
     "start_time": "2024-09-25T12:22:52.994737Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.summary()"
   ],
   "id": "83d8647280b71a53",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001B[38;5;33mDense\u001B[0m)                   │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m24\u001B[0m)          │           \u001B[38;5;34m912\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m24\u001B[0m)          │           \u001B[38;5;34m600\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m, \u001B[38;5;34m4\u001B[0m)           │           \u001B[38;5;34m100\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,612\u001B[0m (6.30 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,612</span> (6.30 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,612\u001B[0m (6.30 KB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,612</span> (6.30 KB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Build Agent wit Keras-RL"
   ],
   "id": "97d8cab3cd58809f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.932406278Z",
     "start_time": "2024-09-25T12:22:53.056255Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#@tf.function(reduce_retracing=True)\n",
    "def build_agent(model, actions):\n",
    "    policy = BoltzmannQPolicy()\n",
    "    memory = SequentialMemory(limit=50000, window_length=1)\n",
    "    dqn = DQNAgent(model=model, memory=memory, policy=policy,\n",
    "                  nb_actions=actions, nb_steps_warmup=10, target_model_update=1e-2)\n",
    "    return dqn"
   ],
   "id": "36752bcb3387eb28",
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "source": [
    "dqn = build_agent(model, actions)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.932514044Z",
     "start_time": "2024-09-25T12:22:53.106952Z"
    }
   },
   "id": "261ea55dd51e628c",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BoltzmannQPolicy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m dqn \u001B[38;5;241m=\u001B[39m \u001B[43mbuild_agent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mactions\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[30], line 3\u001B[0m, in \u001B[0;36mbuild_agent\u001B[0;34m(model, actions)\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbuild_agent\u001B[39m(model, actions):\n\u001B[0;32m----> 3\u001B[0m     policy \u001B[38;5;241m=\u001B[39m \u001B[43mBoltzmannQPolicy\u001B[49m()\n\u001B[1;32m      4\u001B[0m     memory \u001B[38;5;241m=\u001B[39m SequentialMemory(limit\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50000\u001B[39m, window_length\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      5\u001B[0m     dqn \u001B[38;5;241m=\u001B[39m DQNAgent(model\u001B[38;5;241m=\u001B[39mmodel, memory\u001B[38;5;241m=\u001B[39mmemory, policy\u001B[38;5;241m=\u001B[39mpolicy,\n\u001B[1;32m      6\u001B[0m                   nb_actions\u001B[38;5;241m=\u001B[39mactions, nb_steps_warmup\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, target_model_update\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-2\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'BoltzmannQPolicy' is not defined"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "dqn.compile(Adam(learning_rate=1e-3), metrics=['mae'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.932599084Z",
     "start_time": "2024-09-22T22:16:57.238526800Z"
    }
   },
   "id": "92692ff464f3c981"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.932677222Z",
     "start_time": "2024-09-22T22:16:58.040308300Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 5000 steps ...\n",
      "Interval 1 (0 steps performed)\n",
      " 1423/10000 [===>..........................] - ETA: 1:36 - reward: -0.5264done, took 16.064 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x1d02e5392b0>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42,
   "source": [
    "\n",
    "\n",
    "dqn.fit(env, nb_steps=5000, visualize=False, verbose=1)\n"
   ],
   "id": "55edb33778c5ff93"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.932791536Z",
     "start_time": "2024-09-22T22:04:37.103682200Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing for 100 episodes ...\n",
      "Episode 1: reward: 10.000, steps: 60\n",
      "Episode 2: reward: 16.000, steps: 60\n",
      "Episode 3: reward: 6.000, steps: 60\n",
      "Episode 4: reward: 8.000, steps: 60\n",
      "Episode 5: reward: 4.000, steps: 60\n",
      "Episode 6: reward: 18.000, steps: 60\n",
      "Episode 7: reward: -16.000, steps: 60\n",
      "Episode 8: reward: -12.000, steps: 60\n",
      "Episode 9: reward: -8.000, steps: 60\n",
      "Episode 10: reward: -2.000, steps: 60\n",
      "Episode 11: reward: -2.000, steps: 60\n",
      "Episode 12: reward: 8.000, steps: 60\n",
      "Episode 13: reward: -10.000, steps: 60\n",
      "Episode 14: reward: 4.000, steps: 60\n",
      "Episode 15: reward: 2.000, steps: 60\n",
      "Episode 16: reward: 6.000, steps: 60\n",
      "Episode 17: reward: -10.000, steps: 60\n",
      "Episode 18: reward: 0.000, steps: 60\n",
      "Episode 19: reward: 10.000, steps: 60\n",
      "Episode 20: reward: -8.000, steps: 60\n",
      "Episode 21: reward: -6.000, steps: 60\n",
      "Episode 22: reward: 6.000, steps: 60\n",
      "Episode 23: reward: 0.000, steps: 60\n",
      "Episode 24: reward: -2.000, steps: 60\n",
      "Episode 25: reward: 8.000, steps: 60\n",
      "Episode 26: reward: 6.000, steps: 60\n",
      "Episode 27: reward: 4.000, steps: 60\n",
      "Episode 28: reward: 28.000, steps: 60\n",
      "Episode 29: reward: 0.000, steps: 60\n",
      "Episode 30: reward: 8.000, steps: 60\n",
      "Episode 31: reward: 8.000, steps: 60\n",
      "Episode 32: reward: -4.000, steps: 60\n",
      "Episode 33: reward: -2.000, steps: 60\n",
      "Episode 34: reward: -16.000, steps: 60\n",
      "Episode 35: reward: 0.000, steps: 60\n",
      "Episode 36: reward: -22.000, steps: 60\n",
      "Episode 37: reward: 6.000, steps: 60\n",
      "Episode 38: reward: -2.000, steps: 60\n",
      "Episode 39: reward: 10.000, steps: 60\n",
      "Episode 40: reward: -26.000, steps: 60\n",
      "Episode 41: reward: 2.000, steps: 60\n",
      "Episode 42: reward: 8.000, steps: 60\n",
      "Episode 43: reward: 12.000, steps: 60\n",
      "Episode 44: reward: 4.000, steps: 60\n",
      "Episode 45: reward: 2.000, steps: 60\n",
      "Episode 46: reward: -12.000, steps: 60\n",
      "Episode 47: reward: -14.000, steps: 60\n",
      "Episode 48: reward: -6.000, steps: 60\n",
      "Episode 49: reward: 0.000, steps: 60\n",
      "Episode 50: reward: 14.000, steps: 60\n",
      "Episode 51: reward: 8.000, steps: 60\n",
      "Episode 52: reward: 2.000, steps: 60\n",
      "Episode 53: reward: -6.000, steps: 60\n",
      "Episode 54: reward: 2.000, steps: 60\n",
      "Episode 55: reward: 12.000, steps: 60\n",
      "Episode 56: reward: -10.000, steps: 60\n",
      "Episode 57: reward: -14.000, steps: 60\n",
      "Episode 58: reward: 12.000, steps: 60\n",
      "Episode 59: reward: -4.000, steps: 60\n",
      "Episode 60: reward: 0.000, steps: 60\n",
      "Episode 61: reward: 14.000, steps: 60\n",
      "Episode 62: reward: 14.000, steps: 60\n",
      "Episode 63: reward: 8.000, steps: 60\n",
      "Episode 64: reward: 8.000, steps: 60\n",
      "Episode 65: reward: 8.000, steps: 60\n",
      "Episode 66: reward: 10.000, steps: 60\n",
      "Episode 67: reward: 12.000, steps: 60\n",
      "Episode 68: reward: -2.000, steps: 60\n",
      "Episode 69: reward: 12.000, steps: 60\n",
      "Episode 70: reward: -14.000, steps: 60\n",
      "Episode 71: reward: 10.000, steps: 60\n",
      "Episode 72: reward: -16.000, steps: 60\n",
      "Episode 73: reward: 4.000, steps: 60\n",
      "Episode 74: reward: -12.000, steps: 60\n",
      "Episode 75: reward: 8.000, steps: 60\n",
      "Episode 76: reward: 0.000, steps: 60\n",
      "Episode 77: reward: 6.000, steps: 60\n",
      "Episode 78: reward: 12.000, steps: 60\n",
      "Episode 79: reward: -8.000, steps: 60\n",
      "Episode 80: reward: 24.000, steps: 60\n",
      "Episode 81: reward: -6.000, steps: 60\n",
      "Episode 82: reward: 0.000, steps: 60\n",
      "Episode 83: reward: 16.000, steps: 60\n",
      "Episode 84: reward: -4.000, steps: 60\n",
      "Episode 85: reward: 8.000, steps: 60\n",
      "Episode 86: reward: -2.000, steps: 60\n",
      "Episode 87: reward: -20.000, steps: 60\n",
      "Episode 88: reward: 0.000, steps: 60\n",
      "Episode 89: reward: -2.000, steps: 60\n",
      "Episode 90: reward: 0.000, steps: 60\n",
      "Episode 91: reward: -22.000, steps: 60\n",
      "Episode 92: reward: 14.000, steps: 60\n",
      "Episode 93: reward: -2.000, steps: 60\n",
      "Episode 94: reward: 18.000, steps: 60\n",
      "Episode 95: reward: -8.000, steps: 60\n",
      "Episode 96: reward: 10.000, steps: 60\n",
      "Episode 97: reward: 0.000, steps: 60\n",
      "Episode 98: reward: 12.000, steps: 60\n",
      "Episode 99: reward: -6.000, steps: 60\n",
      "Episode 100: reward: -10.000, steps: 60\n",
      "1.34\n"
     ]
    }
   ],
   "execution_count": 23,
   "source": [
    "scores = dqn.test(env, nb_episodes=100, visualize=False)\n",
    "print(np.mean(scores.history['episode_reward']))"
   ],
   "id": "480c28428c2a347a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "892f339dfb0521a2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [],
   "id": "d5d95c43632b1a97"
  },
  {
   "cell_type": "code",
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.933316504Z",
     "start_time": "2024-09-22T14:08:02.664423Z"
    }
   },
   "id": "f8006474c7e95115",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/loz/Documents/GitHub/MSc-Project/final_code'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "#os.listdir()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.933456935Z",
     "start_time": "2024-09-22T18:09:26.754832700Z"
    }
   },
   "id": "3efd9c6ae4abd830",
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "source": [
    "# get pre_trained model of SWaT\n",
    "swat_lstm = tf.keras.models.load_model('swat_lstm_100s.keras')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-25T18:18:30.933542492Z",
     "start_time": "2024-09-22T18:09:05.868741200Z"
    }
   },
   "id": "be505a35c8017c05",
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to synchronously open file (file signature not found)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# get pre_trained model of SWaT\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m swat_lstm \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mswat_lstm_100s.keras\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\venv\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[0;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[1;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[1;32m~\\venv\\lib\\site-packages\\h5py\\_hl\\files.py:562\u001B[0m, in \u001B[0;36mFile.__init__\u001B[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001B[0m\n\u001B[0;32m    553\u001B[0m     fapl \u001B[38;5;241m=\u001B[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001B[0;32m    554\u001B[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001B[0;32m    555\u001B[0m                      alignment_threshold\u001B[38;5;241m=\u001B[39malignment_threshold,\n\u001B[0;32m    556\u001B[0m                      alignment_interval\u001B[38;5;241m=\u001B[39malignment_interval,\n\u001B[0;32m    557\u001B[0m                      meta_block_size\u001B[38;5;241m=\u001B[39mmeta_block_size,\n\u001B[0;32m    558\u001B[0m                      \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    559\u001B[0m     fcpl \u001B[38;5;241m=\u001B[39m make_fcpl(track_order\u001B[38;5;241m=\u001B[39mtrack_order, fs_strategy\u001B[38;5;241m=\u001B[39mfs_strategy,\n\u001B[0;32m    560\u001B[0m                      fs_persist\u001B[38;5;241m=\u001B[39mfs_persist, fs_threshold\u001B[38;5;241m=\u001B[39mfs_threshold,\n\u001B[0;32m    561\u001B[0m                      fs_page_size\u001B[38;5;241m=\u001B[39mfs_page_size)\n\u001B[1;32m--> 562\u001B[0m     fid \u001B[38;5;241m=\u001B[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001B[38;5;241m=\u001B[39mswmr)\n\u001B[0;32m    564\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(libver, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m    565\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_libver \u001B[38;5;241m=\u001B[39m libver\n",
      "File \u001B[1;32m~\\venv\\lib\\site-packages\\h5py\\_hl\\files.py:235\u001B[0m, in \u001B[0;36mmake_fid\u001B[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001B[0m\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m swmr \u001B[38;5;129;01mand\u001B[39;00m swmr_support:\n\u001B[0;32m    234\u001B[0m         flags \u001B[38;5;241m|\u001B[39m\u001B[38;5;241m=\u001B[39m h5f\u001B[38;5;241m.\u001B[39mACC_SWMR_READ\n\u001B[1;32m--> 235\u001B[0m     fid \u001B[38;5;241m=\u001B[39m \u001B[43mh5f\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfapl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfapl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m mode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr+\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    237\u001B[0m     fid \u001B[38;5;241m=\u001B[39m h5f\u001B[38;5;241m.\u001B[39mopen(name, h5f\u001B[38;5;241m.\u001B[39mACC_RDWR, fapl\u001B[38;5;241m=\u001B[39mfapl)\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\\\h5f.pyx:102\u001B[0m, in \u001B[0;36mh5py.h5f.open\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mOSError\u001B[0m: Unable to synchronously open file (file signature not found)"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "478f1bc17bca7a69"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
